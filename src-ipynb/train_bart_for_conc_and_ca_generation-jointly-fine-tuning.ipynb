{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is to jointly train BART-v2 model for both generating the conclusion and the counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on transformers v4.9.1 and datasets v1.10.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "from utils import *\n",
    "from mt_bart_v2 import *\n",
    "\n",
    "print(f\"Running on transformers v{transformers.__version__} and datasets v{datasets.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "import ray\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_init(params):\n",
    "    compute_dynamic_weights=False\n",
    "    conc_loss_weight=0.5 if params == None else params['conc_loss_weight']\n",
    "    counter_loss_weight=0.5 if params == None else params['counter_loss_weight']\n",
    "    attention_to_conc=False\n",
    "    conc_decoder=True\n",
    "    \n",
    "    model     = BartModelV2.from_pretrained('facebook/bart-base', compute_dynamic_weights=compute_dynamic_weights, \n",
    "                                            conc_loss_weight = conc_loss_weight, \n",
    "                                            counter_loss_weight=counter_loss_weight, \n",
    "                                            attention_to_conc=attention_to_conc, \n",
    "                                            conc_decoder=conc_decoder).to(device)\n",
    "    \n",
    "    original_bart_model = BartModel.from_pretrained('facebook/bart-base').to(device)\n",
    "\n",
    "    #load the weights of the two decoders\n",
    "    model.conclusion_decoder.load_state_dict(original_bart_model.decoder.state_dict())\n",
    "    model.counter_decoder.load_state_dict(original_bart_model.decoder.state_dict())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold = '../../../data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking unique posts from valid dataset and sample only 1500 instances\n",
    "# valid_df = pd.read_pickle(data_fold+'/reddit_data/conclusion_and_ca_generation/valid_conclusion_comp_remove_75sem_perc.pkl')\n",
    "# valid_unique_df = valid_df.drop_duplicates('post_id')\n",
    "# valid_sample_df = valid_unique_df.sample(1500)\n",
    "# valid_sample_df.to_pickle(data_fold+'/reddit_data/conclusion_and_ca_generation/valid_conclusion_comp_remove_75sem_perc_sample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(pd.read_pickle(data_fold+'/reddit_data/conclusion_and_ca_generation/train_conclusion_comp_remove_75sem_perc.pkl'))\n",
    "valid_ds = Dataset.from_pandas(pd.read_pickle(data_fold+'/reddit_data/conclusion_and_ca_generation/valid_conclusion_comp_remove_75sem_perc_sample.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding function for joint generation of conclusion and counter\n",
    "def preprocess_function(examples, tokenizer, premises_clm, counter_clm, conclusion_clm, max_input_length=512, max_conc_length=100, max_counter_length=200):\n",
    "    premises   = examples[premises_clm]\n",
    "    conclusions = examples[conclusion_clm]\n",
    "    counters = examples[counter_clm]\n",
    "    \n",
    "        \n",
    "    premises = [' '.join(x) for x in premises] if isinstance(premises[0], list) else premises\n",
    "    counters = [' '.join(x) for x in counters] if isinstance(counters[0], list) else counters\n",
    "    conclusions = [' '.join(x) for x in conclusions] if isinstance(conclusions[0], list) else conclusions\n",
    "    \n",
    "    model_inputs = tokenizer(premises, max_length=max_input_length, truncation=True, padding='max_length')\n",
    "        \n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        counter_labels = tokenizer(counters, max_length=max_counter_length, truncation=True, padding='max_length')\n",
    "        conclusion_labels = tokenizer(conclusions, max_length=max_conc_length, truncation=True, padding='max_length')\n",
    "\n",
    "    model_inputs[\"conclusion_labels\"] = conclusion_labels[\"input_ids\"]\n",
    "    model_inputs[\"counter_labels\"] = counter_labels[\"input_ids\"]\n",
    "    model_inputs[\"counter_decoder_attention_mask\"] = counter_labels['attention_mask']\n",
    "    model_inputs[\"conclusion_decoder_attention_mask\"] = conclusion_labels['attention_mask']\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample the training dataset\n",
    "tmp_ds = train_ds.train_test_split(0.005)\n",
    "train_ds = tmp_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a470c69c5a534df48fd447fdfe576da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b30df4c03be4901816bf0a3716176a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized_ds = train_ds.map(lambda x :preprocess_function(x, tokenizer, 'masked_premises', 'counter', 'title'), batched=True)\n",
    "valid_tokenized_ds = valid_ds.map(lambda x :preprocess_function(x, tokenizer, 'masked_premises', 'counter', 'title'), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1d5f7c915158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorForSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/2021//sile2804/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.da0f3c0e2dc1c2fecc46738a1ebf4806f2fc36aae3d5c1947f21e063e7cab34b\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/2021//sile2804/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "Some weights of the model checkpoint at facebook/bart-base were not used when initializing BartModelV2: ['decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.4.fc1.bias', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.5.fc2.bias', 'decoder.layernorm_embedding.bias', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.embed_tokens.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.0.fc2.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.2.fc2.weight', 'decoder.layers.1.fc2.weight', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.1.fc1.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.embed_positions.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.3.fc1.weight', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.5.fc1.bias', 'decoder.layernorm_embedding.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.5.fc2.weight', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.3.fc2.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.fc1.bias', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.fc2.bias', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight']\n",
      "- This IS expected if you are initializing BartModelV2 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModelV2 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartModelV2 were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['conclusion_decoder.layers.4.encoder_attn.out_proj.bias', 'counter_decoder.layers.2.encoder_attn.v_proj.bias', 'conclusion_decoder.layers.2.self_attn.q_proj.bias', 'counter_decoder.layers.3.encoder_attn.k_proj.bias', 'conclusion_decoder.layers.3.fc2.bias', 'conclusion_decoder.layers.5.self_attn.v_proj.bias', 'counter_decoder.layers.3.self_attn.q_proj.bias', 'conclusion_decoder.layers.1.self_attn_layer_norm.weight', 'conclusion_decoder.layers.3.encoder_attn_layer_norm.bias', 'conclusion_decoder.layers.5.self_attn.out_proj.weight', 'counter_decoder.layers.5.encoder_attn.v_proj.bias', 'counter_decoder.layers.4.encoder_attn.k_proj.bias', 'conclusion_decoder.layernorm_embedding.bias', 'counter_decoder.layers.2.self_attn.k_proj.weight', 'counter_decoder.layers.0.encoder_attn.out_proj.weight', 'conclusion_decoder.layers.2.fc1.weight', 'counter_decoder.layers.2.encoder_attn.q_proj.bias', 'conclusion_decoder.layers.4.encoder_attn_layer_norm.bias', 'counter_decoder.layers.1.self_attn_layer_norm.bias', 'conclusion_decoder.layers.3.self_attn.out_proj.weight', 'conclusion_decoder.embed_tokens.weight', 'counter_decoder.layers.3.fc1.bias', 'counter_decoder.layers.4.self_attn.q_proj.bias', 'counter_decoder.layers.4.self_attn.out_proj.bias', 'conclusion_decoder.layers.1.encoder_attn.q_proj.weight', 'counter_decoder.layers.4.encoder_attn.out_proj.bias', 'counter_decoder.layers.1.self_attn.v_proj.bias', 'conclusion_decoder.embed_positions.weight', 'counter_decoder.layers.1.encoder_attn_layer_norm.weight', 'counter_decoder.layers.2.encoder_attn.k_proj.bias', 'conclusion_decoder.layers.4.encoder_attn.q_proj.bias', 'counter_decoder.layers.5.encoder_attn.q_proj.bias', 'counter_decoder.layers.5.self_attn.v_proj.bias', 'counter_decoder.layers.5.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.3.final_layer_norm.bias', 'conc_lm_head.weight', 'counter_decoder.layers.5.fc1.bias', 'conclusion_decoder.layers.0.encoder_attn.v_proj.bias', 'counter_decoder.layers.2.self_attn_layer_norm.weight', 'counter_decoder.layers.4.final_layer_norm.weight', 'counter_decoder.layers.0.encoder_attn.q_proj.weight', 'conclusion_decoder.layers.3.self_attn.k_proj.weight', 'conclusion_decoder.layers.3.encoder_attn.v_proj.weight', 'conclusion_decoder.layers.0.encoder_attn.q_proj.weight', 'conclusion_decoder.layers.2.final_layer_norm.weight', 'counter_decoder.layers.5.encoder_attn_layer_norm.bias', 'counter_decoder.layers.0.encoder_attn.q_proj.bias', 'conclusion_decoder.layers.1.self_attn_layer_norm.bias', 'counter_decoder.layers.5.fc2.weight', 'conclusion_decoder.layers.2.final_layer_norm.bias', 'counter_decoder.layers.2.encoder_attn.k_proj.weight', 'counter_decoder.layers.5.self_attn_layer_norm.bias', 'conclusion_decoder.layers.0.encoder_attn.k_proj.weight', 'counter_decoder.layers.4.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.0.fc1.weight', 'conclusion_decoder.layers.3.encoder_attn.k_proj.weight', 'counter_decoder.layers.1.fc1.bias', 'conclusion_decoder.layers.0.encoder_attn.v_proj.weight', 'conclusion_decoder.layers.5.encoder_attn_layer_norm.weight', 'counter_decoder.layers.5.encoder_attn.q_proj.weight', 'counter_decoder.layers.3.encoder_attn.v_proj.weight', 'counter_decoder.layers.3.final_layer_norm.weight', 'counter_decoder.layers.0.encoder_attn_layer_norm.bias', 'conclusion_decoder.layers.5.self_attn.k_proj.weight', 'counter_decoder.layers.0.self_attn.k_proj.bias', 'conclusion_decoder.layers.5.fc1.bias', 'conclusion_decoder.layers.2.encoder_attn.q_proj.bias', 'counter_decoder.layers.5.self_attn.out_proj.weight', 'conclusion_decoder.layers.1.encoder_attn.v_proj.weight', 'counter_decoder.layers.5.self_attn.q_proj.bias', 'conclusion_decoder.layers.5.fc1.weight', 'counter_decoder.layers.4.encoder_attn_layer_norm.bias', 'conclusion_decoder.layers.2.self_attn.out_proj.bias', 'conclusion_decoder.layers.2.encoder_attn.v_proj.bias', 'counter_decoder.layers.5.final_layer_norm.bias', 'conclusion_decoder.layers.0.fc2.bias', 'conclusion_decoder.layers.4.encoder_attn.v_proj.bias', 'conclusion_decoder.layers.2.encoder_attn.out_proj.weight', 'counter_decoder.layers.3.encoder_attn.v_proj.bias', 'counter_decoder.layers.0.encoder_attn.v_proj.weight', 'conclusion_decoder.layers.3.final_layer_norm.weight', 'counter_decoder.layers.2.fc2.bias', 'conclusion_decoder.layers.0.self_attn.q_proj.bias', 'conclusion_decoder.layers.1.final_layer_norm.bias', 'conclusion_decoder.layers.5.encoder_attn_layer_norm.bias', 'counter_decoder.layers.3.self_attn.out_proj.bias', 'counter_decoder.layers.5.self_attn.k_proj.weight', 'conclusion_decoder.layers.3.encoder_attn.q_proj.bias', 'conclusion_decoder.layers.1.encoder_attn.k_proj.bias', 'counter_decoder.layers.4.self_attn.out_proj.weight', 'counter_decoder.layers.2.self_attn.q_proj.bias', 'counter_decoder.layers.0.self_attn.v_proj.bias', 'conclusion_decoder.layers.5.encoder_attn.v_proj.bias', 'counter_decoder.layers.1.encoder_attn.out_proj.bias', 'counter_decoder.layers.0.self_attn_layer_norm.bias', 'conclusion_decoder.layers.2.fc2.bias', 'counter_decoder.layers.0.self_attn.out_proj.weight', 'counter_decoder.layers.2.encoder_attn_layer_norm.bias', 'counter_decoder.layers.1.final_layer_norm.weight', 'conclusion_decoder.layers.0.encoder_attn.out_proj.weight', 'counter_decoder.layers.5.fc2.bias', 'conclusion_decoder.layers.0.self_attn_layer_norm.bias', 'conclusion_decoder.layers.5.final_layer_norm.weight', 'conclusion_decoder.layers.2.encoder_attn.k_proj.bias', 'conclusion_decoder.layers.1.encoder_attn.out_proj.bias', 'conclusion_decoder.layers.0.encoder_attn_layer_norm.bias', 'counter_decoder.layers.3.fc2.bias', 'counter_decoder.layers.3.encoder_attn.q_proj.weight', 'conclusion_decoder.layers.5.encoder_attn.q_proj.weight', 'conclusion_decoder.layers.0.self_attn.out_proj.weight', 'conclusion_decoder.layers.3.self_attn.q_proj.bias', 'conclusion_decoder.layers.1.encoder_attn.v_proj.bias', 'conclusion_decoder.layers.4.self_attn.k_proj.bias', 'conclusion_decoder.layers.4.encoder_attn.v_proj.weight', 'counter_decoder.layers.0.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.5.fc2.weight', 'conclusion_decoder.layers.4.self_attn_layer_norm.weight', 'counter_decoder.layers.3.self_attn.k_proj.bias', 'counter_decoder.layers.4.encoder_attn.v_proj.weight', 'counter_decoder.layers.5.encoder_attn.k_proj.weight', 'conclusion_decoder.layers.4.encoder_attn.q_proj.weight', 'conclusion_decoder.layers.3.encoder_attn.out_proj.weight', 'conclusion_decoder.layers.2.fc1.bias', 'conclusion_decoder.layers.0.final_layer_norm.weight', 'counter_decoder.layers.4.encoder_attn.out_proj.weight', 'conclusion_decoder.layers.0.fc2.weight', 'conclusion_decoder.layers.1.fc1.bias', 'conclusion_decoder.layers.1.fc2.bias', 'counter_decoder.layers.4.self_attn.v_proj.weight', 'conclusion_decoder.layers.2.encoder_attn.k_proj.weight', 'counter_decoder.layers.2.encoder_attn.out_proj.weight', 'conclusion_decoder.layers.3.encoder_attn.k_proj.bias', 'conclusion_decoder.layers.3.self_attn.q_proj.weight', 'counter_decoder.layernorm_embedding.weight', 'conclusion_decoder.layers.0.self_attn.out_proj.bias', 'conclusion_decoder.layers.5.encoder_attn.k_proj.weight', 'conclusion_decoder.layers.1.encoder_attn.q_proj.bias', 'counter_decoder.layers.3.self_attn_layer_norm.bias', 'conclusion_decoder.layers.5.self_attn.out_proj.bias', 'counter_decoder.layers.1.self_attn.out_proj.bias', 'conclusion_decoder.layers.2.self_attn.q_proj.weight', 'conclusion_decoder.layers.3.fc1.bias', 'conclusion_decoder.layers.1.self_attn.k_proj.bias', 'counter_decoder.layers.3.encoder_attn.out_proj.weight', 'counter_decoder.layers.0.self_attn.q_proj.bias', 'conclusion_decoder.layers.0.encoder_attn.out_proj.bias', 'counter_decoder.layers.0.final_layer_norm.bias', 'conclusion_decoder.layers.1.self_attn.k_proj.weight', 'conclusion_decoder.layers.1.self_attn.v_proj.weight', 'counter_decoder.layers.4.encoder_attn.q_proj.bias', 'conclusion_decoder.layers.4.fc1.bias', 'conclusion_decoder.layers.3.encoder_attn.out_proj.bias', 'counter_decoder.layers.4.self_attn.k_proj.bias', 'counter_decoder.layers.1.encoder_attn_layer_norm.bias', 'conclusion_decoder.layers.1.fc2.weight', 'conclusion_decoder.layers.5.final_layer_norm.bias', 'conclusion_decoder.layers.5.fc2.bias', 'counter_decoder.layers.5.encoder_attn.out_proj.weight', 'counter_decoder.layers.4.fc1.weight', 'conclusion_decoder.layers.1.self_attn.q_proj.bias', 'counter_decoder.layers.1.encoder_attn.q_proj.weight', 'counter_decoder.layers.2.fc1.weight', 'counter_decoder.layers.2.self_attn.v_proj.weight', 'conclusion_decoder.layers.2.self_attn.k_proj.weight', 'counter_decoder.layers.5.self_attn.v_proj.weight', 'conclusion_decoder.layers.3.fc1.weight', 'counter_decoder.layers.3.final_layer_norm.bias', 'counter_decoder.layers.4.self_attn.q_proj.weight', 'counter_decoder.layers.1.final_layer_norm.bias', 'conclusion_decoder.layers.5.encoder_attn.out_proj.weight', 'counter_decoder.layers.3.self_attn.q_proj.weight', 'counter_decoder.layers.0.fc1.bias', 'counter_decoder.layers.3.encoder_attn.k_proj.weight', 'counter_decoder.layers.0.fc2.bias', 'conclusion_decoder.layers.4.fc2.weight', 'counter_decoder.layers.5.self_attn_layer_norm.weight', 'counter_decoder.layers.2.encoder_attn.v_proj.weight', 'counter_decoder.layers.3.encoder_attn_layer_norm.bias', 'conclusion_decoder.layers.0.self_attn.k_proj.weight', 'counter_decoder.layers.1.fc2.bias', 'conclusion_decoder.layers.0.self_attn.q_proj.weight', 'conclusion_decoder.layers.5.self_attn.k_proj.bias', 'counter_decoder.layers.2.self_attn.out_proj.bias', 'counter_decoder.layers.1.self_attn.k_proj.bias', 'counter_decoder.layers.4.self_attn.v_proj.bias', 'counter_decoder.layers.2.fc1.bias', 'conclusion_decoder.layers.4.self_attn.q_proj.weight', 'counter_decoder.layers.5.encoder_attn.out_proj.bias', 'conclusion_decoder.layers.2.self_attn.v_proj.weight', 'counter_decoder.layers.0.self_attn.out_proj.bias', 'counter_decoder.layers.4.self_attn.k_proj.weight', 'conclusion_decoder.layers.0.encoder_attn.q_proj.bias', 'counter_decoder.embed_positions.weight', 'conclusion_decoder.layers.4.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.1.self_attn.out_proj.bias', 'counter_decoder.layers.0.encoder_attn.v_proj.bias', 'counter_decoder.layers.2.encoder_attn.q_proj.weight', 'conclusion_decoder.layers.3.self_attn_layer_norm.weight', 'conclusion_decoder.layers.5.encoder_attn.k_proj.bias', 'counter_decoder.layers.0.self_attn.v_proj.weight', 'conclusion_decoder.layers.4.self_attn.q_proj.bias', 'counter_decoder.layers.4.fc2.weight', 'counter_decoder.layers.3.self_attn.v_proj.weight', 'conclusion_decoder.layers.2.self_attn_layer_norm.weight', 'counter_decoder.layers.3.encoder_attn.q_proj.bias', 'conclusion_decoder.layers.0.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.1.self_attn.v_proj.bias', 'counter_decoder.layers.1.encoder_attn.out_proj.weight', 'counter_decoder.layers.3.fc1.weight', 'counter_decoder.embed_tokens.weight', 'conclusion_decoder.layers.5.self_attn_layer_norm.bias', 'conclusion_decoder.layers.4.final_layer_norm.bias', 'counter_decoder.layers.2.self_attn_layer_norm.bias', 'conclusion_decoder.layers.1.encoder_attn.out_proj.weight', 'conclusion_decoder.layers.0.fc1.bias', 'counter_decoder.layers.0.self_attn.k_proj.weight', 'counter_decoder.layers.1.fc2.weight', 'counter_decoder.layers.5.self_attn.out_proj.bias', 'conclusion_decoder.layers.2.self_attn_layer_norm.bias', 'conclusion_decoder.layers.2.fc2.weight', 'conclusion_decoder.layers.5.encoder_attn.out_proj.bias', 'conclusion_decoder.layers.1.final_layer_norm.weight', 'conclusion_decoder.layers.5.encoder_attn.v_proj.weight', 'counter_decoder.layers.4.final_layer_norm.bias', 'conclusion_decoder.layers.2.encoder_attn.v_proj.weight', 'counter_decoder.layers.4.self_attn_layer_norm.weight', 'conclusion_decoder.layers.2.encoder_attn.out_proj.bias', 'counter_decoder.layers.4.encoder_attn.v_proj.bias', 'counter_decoder.layers.5.encoder_attn.v_proj.weight', 'counter_decoder.layers.1.encoder_attn.k_proj.bias', 'counter_decoder.layers.3.fc2.weight', 'counter_decoder.layers.0.encoder_attn.k_proj.bias', 'counter_decoder.layers.1.encoder_attn.v_proj.bias', 'conclusion_decoder.layers.0.self_attn.k_proj.bias', 'conclusion_decoder.layers.4.encoder_attn.k_proj.bias', 'counter_decoder.layers.1.self_attn.q_proj.bias', 'counter_decoder.layers.3.self_attn_layer_norm.weight', 'counter_decoder.layers.5.self_attn.q_proj.weight', 'conclusion_decoder.layers.2.encoder_attn.q_proj.weight', 'counter_decoder.layers.5.encoder_attn.k_proj.bias', 'conclusion_decoder.layers.2.self_attn.out_proj.weight', 'conclusion_decoder.layers.3.self_attn.k_proj.bias', 'counter_decoder.layers.1.fc1.weight', 'counter_decoder.layers.1.self_attn_layer_norm.weight', 'conclusion_decoder.layers.4.encoder_attn.k_proj.weight', 'conclusion_decoder.layers.2.self_attn.k_proj.bias', 'counter_decoder.layers.4.encoder_attn.k_proj.weight', 'counter_decoder.layers.3.encoder_attn.out_proj.bias', 'counter_decoder.layers.1.encoder_attn.k_proj.weight', 'counter_decoder.layers.2.final_layer_norm.bias', 'conclusion_decoder.layers.4.encoder_attn.out_proj.weight', 'counter_decoder.layers.5.self_attn.k_proj.bias', 'counter_decoder.layers.1.encoder_attn.v_proj.weight', 'conclusion_decoder.layers.1.self_attn.out_proj.weight', 'conclusion_decoder.layers.4.self_attn_layer_norm.bias', 'conclusion_decoder.layers.5.self_attn.q_proj.bias', 'conclusion_decoder.layers.0.final_layer_norm.bias', 'conclusion_decoder.layers.4.self_attn.out_proj.weight', 'counter_decoder.layers.2.final_layer_norm.weight', 'conclusion_decoder.layernorm_embedding.weight', 'counter_decoder.layers.1.self_attn.out_proj.weight', 'conclusion_decoder.layers.3.encoder_attn.v_proj.bias', 'counter_decoder.layers.0.encoder_attn.out_proj.bias', 'counter_decoder.layers.5.fc1.weight', 'counter_decoder.layers.1.encoder_attn.q_proj.bias', 'count_lm_head.weight', 'counter_decoder.layernorm_embedding.bias', 'counter_decoder.layers.2.encoder_attn.out_proj.bias', 'conclusion_decoder.layers.4.fc2.bias', 'counter_decoder.layers.4.encoder_attn.q_proj.weight', 'counter_decoder.layers.3.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.3.self_attn_layer_norm.bias', 'conclusion_decoder.layers.5.encoder_attn.q_proj.bias', 'conclusion_decoder.layers.3.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.4.self_attn.out_proj.bias', 'counter_decoder.layers.0.fc2.weight', 'final_logits_bias', 'conclusion_decoder.layers.1.self_attn.q_proj.weight', 'counter_decoder.layers.4.self_attn_layer_norm.bias', 'counter_decoder.layers.4.fc2.bias', 'conclusion_decoder.layers.1.encoder_attn_layer_norm.bias', 'conclusion_decoder.layers.3.encoder_attn.q_proj.weight', 'counter_decoder.layers.2.self_attn.q_proj.weight', 'counter_decoder.layers.0.self_attn_layer_norm.weight', 'counter_decoder.layers.0.fc1.weight', 'conclusion_decoder.layers.4.self_attn.k_proj.weight', 'conclusion_decoder.layers.2.encoder_attn_layer_norm.bias', 'conclusion_decoder.layers.4.fc1.weight', 'conclusion_decoder.layers.2.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.3.fc2.weight', 'conclusion_decoder.layers.4.self_attn.v_proj.weight', 'counter_decoder.layers.2.self_attn.out_proj.weight', 'counter_decoder.layers.4.fc1.bias', 'counter_decoder.layers.2.self_attn.k_proj.bias', 'counter_decoder.layers.2.encoder_attn_layer_norm.weight', 'conclusion_decoder.layers.2.self_attn.v_proj.bias', 'conclusion_decoder.layers.0.encoder_attn.k_proj.bias', 'conclusion_decoder.layers.5.self_attn_layer_norm.weight', 'counter_decoder.layers.1.self_attn.v_proj.weight', 'counter_decoder.layers.0.final_layer_norm.weight', 'conclusion_decoder.layers.3.self_attn.v_proj.weight', 'conclusion_decoder.layers.0.self_attn.v_proj.bias', 'conclusion_decoder.layers.4.self_attn.v_proj.bias', 'counter_decoder.layers.1.self_attn.k_proj.weight', 'conclusion_decoder.layers.1.encoder_attn.k_proj.weight', 'conclusion_decoder.layers.5.self_attn.q_proj.weight', 'counter_decoder.layers.0.encoder_attn.k_proj.weight', 'counter_decoder.layers.2.fc2.weight', 'conclusion_decoder.layers.4.final_layer_norm.weight', 'counter_decoder.layers.5.final_layer_norm.weight', 'counter_decoder.layers.0.self_attn.q_proj.weight', 'conclusion_decoder.layers.0.self_attn_layer_norm.weight', 'conclusion_decoder.layers.1.encoder_attn_layer_norm.weight', 'counter_decoder.layers.3.self_attn.v_proj.bias', 'conclusion_decoder.layers.3.self_attn.out_proj.bias', 'counter_decoder.layers.2.self_attn.v_proj.bias', 'conclusion_decoder.layers.3.self_attn.v_proj.bias', 'counter_decoder.layers.3.self_attn.out_proj.weight', 'counter_decoder.layers.3.self_attn.k_proj.weight', 'conclusion_decoder.layers.0.self_attn.v_proj.weight', 'conclusion_decoder.layers.1.fc1.weight', 'conclusion_decoder.layers.5.self_attn.v_proj.weight', 'counter_decoder.layers.1.self_attn.q_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/2021//sile2804/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.da0f3c0e2dc1c2fecc46738a1ebf4806f2fc36aae3d5c1947f21e063e7cab34b\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/2021//sile2804/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "All model checkpoint weights were used when initializing BartModel.\n",
      "\n",
      "All the weights of BartModel were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    \"../data/output/joint-con-counter-bart-model-test\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=6,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    metric_for_best_model='bert-fscore',\n",
    "    label_names=['conclusion_labels', 'counter_labels']\n",
    ")\n",
    "\n",
    "trainer = Seq2TwoSeqTrainer(\n",
    "    None,\n",
    "    args,\n",
    "    model_init=model_init,\n",
    "    train_dataset=train_tokenized_ds,\n",
    "    eval_dataset=valid_tokenized_ds,\n",
    "    #data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=lambda x : compute_metrics(x, tokenizer)\n",
    ")\n",
    "\n",
    "#Hyper params truning....\n",
    "\n",
    "tune_config = {\n",
    "    \"per_device_train_batch_size\": [8, 16, 32],\n",
    "    \"per_device_eval_batch_size\": 32\n",
    "}\n",
    "\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=\"bert-fscore\",\n",
    "    mode=\"max\",\n",
    "    perturbation_interval=1,\n",
    "    hyperparam_mutations={\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
    "        \"per_device_train_batch_size\": [8, 16, 32],\n",
    "        \"conc_loss_weight\": tune.uniform(0, 0.5),\n",
    "        \"counter_loss_weight\": tune.uniform(0.5, 1.0),\n",
    "    })\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns={\n",
    "        \"weight_decay\": \"w_decay\",\n",
    "        \"learning_rate\": \"lr\",\n",
    "        \"per_device_train_batch_size\": \"train_bs/gpu\",\n",
    "        \"conc_loss_weight\": \"conc_loss_weight\",\n",
    "        \"counter_loss_weight\": \"counter_loss_weight\"\n",
    "    },\n",
    "    metric_columns=[\n",
    "        \"eval_bert-fscore\", \"eval_loss\", \"steps\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `resources_per_trial` arg was passed into `hyperparameter_search`. Setting it to a default value of 1 CPU for each trial.\n",
      "2022-01-28 11:47:51,151\tINFO utils.py:522 -- Detected RAY_USE_MULTIPROCESSING_CPU_COUNT=1: Using multiprocessing.cpu_count() to detect the number of CPUs. This may be inconsistent when used inside docker. To correctly detect CPUs, unset the env var: `RAY_USE_MULTIPROCESSING_CPU_COUNT`.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pickle' has no attribute 'PickleBuffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-61a84d3e3f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"~/ray_results/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tune_transformer_pbt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlog_to_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0mrun_hp_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_hp_search_optuna\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHPSearchBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTUNA\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrun_hp_search_ray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m         \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/integrations.py\u001b[0m in \u001b[0;36mrun_hp_search_ray\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial_executor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTrialExecutor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0m_ray_auto_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_remote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36m_ray_auto_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    752\u001b[0m                     \u001b[0;34m\"For cluster usage or custom Ray initialization, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \"call `ray.init(...)` before `tune.run`.\")\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, _enable_object_reconstruction, _redis_max_memory, _plasma_directory, _node_ip_address, _driver_object_store_memory, _memory, _redis_password, _temp_dir, _metrics_export_port, _system_config, _tracing_startup_hook, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_post_init_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_node_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/registry.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_flush\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(value, _owner)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m             object_ref = worker.put_object(\n\u001b[0;32m-> 1776\u001b[0;31m                 value, owner_address=serialize_owner_address)\n\u001b[0m\u001b[1;32m   1777\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mObjectStoreFullError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m             logger.info(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mput_object\u001b[0;34m(self, value, object_ref, owner_address)\u001b[0m\n\u001b[1;32m    291\u001b[0m                                         \"inserting with an ObjectRef\")\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mserialized_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_serialization_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# This *must* be the first place that we construct this python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# ObjectRef because an entry with 0 local references is created when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/serialization.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mRawSerializedObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize_to_msgpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/serialization.py\u001b[0m in \u001b[0;36m_serialize_to_msgpack\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_METADATA_TYPE_PYTHON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mpickle5_serialized_object\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize_to_pickle5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpython_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mpickle5_serialized_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/serialization.py\u001b[0m in \u001b[0;36m_serialize_to_pickle5\u001b[0;34m(self, metadata, value)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_and_clear_contained_object_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_out_of_band_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/serialization.py\u001b[0m in \u001b[0;36m_serialize_to_pickle5\u001b[0;34m(self, metadata, value)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_in_band_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             inband = pickle.dumps(\n\u001b[0;32m--> 298\u001b[0;31m                 value, protocol=5, buffer_callback=writer.buffer_callback)\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_and_clear_contained_object_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"recursion\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Buffer.__reduce_ex__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pickle' has no attribute 'PickleBuffer'"
     ]
    }
   ],
   "source": [
    "best_trial = trainer.hyperparameter_search(\n",
    "    hp_space=lambda _: tune_config,\n",
    "    backend=\"ray\",\n",
    "    n_trials=10,\n",
    "    scheduler=scheduler,\n",
    "    keep_checkpoints_num=1,\n",
    "    checkpoint_score_attr=\"training_iteration\",\n",
    "    progress_reporter=reporter,\n",
    "    local_dir=\"~/ray_results/\",\n",
    "    name=\"tune_transformer_pbt\",\n",
    "    log_to_file=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
