{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from argparse import Namespace\n",
    "\n",
    "sys.path.append('../src-py/')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from utils import *\n",
    "from project_debater_api import *\n",
    "from mt_bart_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceph_dir = '/home/sile2804/data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation'\n",
    "local_home_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_attacks(ds, model, tokenizer, premises_clm, conclusion_clm, gen_kwargs, skip_special_tokens=True, batch_size=16):\n",
    "    ds = ds.map(lambda x :preprocess_function(x, tokenizer, premises_clm, 'counter', conclusion_clm=conclusion_clm), batched=True)\n",
    "    ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    dataloader = torch.utils.data.DataLoader(ds, batch_size=batch_size)\n",
    "    attacks = generate_counters(model, tokenizer, dataloader, gen_kwargs, skip_special_tokens=skip_special_tokens)\n",
    "    \n",
    "    return attacks\n",
    "\n",
    "def create_predictions_df(reddit_sample_valid_ds, gen_kwargs, premises_clm='masked_premises'):\n",
    "    \n",
    "    joint_attacks       = generate_ds_attacks(reddit_sample_valid_ds, join_model, join_model_tokenizer, premises_clm, None, gen_kwargs)\n",
    "    known_conc_attacks  = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, 'title', gen_kwargs)\n",
    "    bart_conc_attacks   = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, 'bart_conclusion', gen_kwargs)\n",
    "    arglex_conc_attacks = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, 'arglex_rank_conclusion', gen_kwargs)\n",
    "    masked_conc_attacks = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, None, gen_kwargs)\n",
    "    \n",
    "    #update max_gen_length to account to the generated conclusion\n",
    "    gen_kwargs['max_length'] = gen_kwargs['max_length'] + 30\n",
    "    joint_conc_baseline_attacks  = generate_ds_attacks(reddit_sample_valid_ds, pred_conclusion_model, pred_conclusion_tokenizer, premises_clm, None, gen_kwargs, skip_special_tokens=False)\n",
    "    #This model would predict the conclusion and then the counter in one sequence.\n",
    "\n",
    "    reddit_pred_df = pd.DataFrame(list(zip(\n",
    "                                           reddit_sample_valid_ds['post_id'],\n",
    "                                           reddit_sample_valid_ds['title'], \n",
    "                                           reddit_sample_valid_ds['conclusion_targets'],\n",
    "                                           reddit_sample_valid_ds['conclusion_stance'],\n",
    "                                           reddit_sample_valid_ds['bart_conclusion'], \n",
    "                                           reddit_sample_valid_ds['arglex_rank_conclusion'], \n",
    "                                           reddit_sample_valid_ds[premises_clm],\n",
    "                                           reddit_sample_valid_ds['counter'], \n",
    "                                           known_conc_attacks, masked_conc_attacks, \n",
    "                                           bart_conc_attacks, arglex_conc_attacks, joint_attacks, joint_conc_baseline_attacks)), \n",
    "                    columns=['post_id', 'conclusion', 'conclusion_target', 'conclusion_stance', 'bart_conclusion', 'arglex_rank_conclusion', 'premises', 'gt_attack', 'known_conc_attacks', \n",
    "                             'masked_conc_attacks', 'bart_conc_attacks', 'arglex_conc_attacks', 'joint_conc_attacks', 'joint_conc_baseline_attacks'])\n",
    "\n",
    "    reddit_pred_df['argument'] = reddit_pred_df.apply(lambda row: row['conclusion'] + ' : ' + ' '.join(row['premises']), axis=1)\n",
    "    reddit_pred_df['premises'] = reddit_pred_df['premises'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    #process the jointly generated conclusion and counter\n",
    "    reddit_pred_df['joint_conc_baseline'] = reddit_pred_df['joint_conc_baseline_attacks'].apply (lambda x: x.split('<counter>')[0])\n",
    "    reddit_pred_df['joint_conc_baseline_attacks'] = reddit_pred_df['joint_conc_baseline_attacks'].apply (lambda x: x.split('<counter>')[1] if '<counter>' in x else x)\n",
    "    reddit_pred_df['joint_conc_baseline'] = reddit_pred_df['joint_conc_baseline'].apply (lambda x: re.sub('<s>|</s>|<conclusion>|<counter>|<pad>', '', x).strip())\n",
    "    reddit_pred_df['joint_conc_baseline_attacks'] = reddit_pred_df['joint_conc_baseline_attacks'].apply (lambda x: re.sub('<s>|</s>|<conclusion>|<counter>|<pad>', '', x).strip())\n",
    "\n",
    "    return reddit_pred_df\n",
    "\n",
    "def get_evaluation_results(reddit_pred_df, df_path):\n",
    "    \n",
    "    #collect references\n",
    "    df = pd.read_pickle(df_path)\n",
    "    arg_counters = df.groupby('post_id').agg({\n",
    "        'counter': lambda x: [' '.join(c) for c in x[0:10]]\n",
    "    }).reset_index()\n",
    "\n",
    "    arg_counters = pd.Series(arg_counters.counter.values, index=arg_counters.post_id).to_dict()\n",
    "\n",
    "    reddit_pred_df['gt_attack'] = reddit_pred_df['gt_attack'].apply(lambda x: str(x))\n",
    "    reddit_pred_df['all_counters'] = reddit_pred_df['post_id'].apply(lambda x: arg_counters[x])\n",
    "    reddit_pred_df = reddit_pred_df[reddit_pred_df.all_counters.map(len) > 0]\n",
    "\n",
    "    masked_conc_eval = evaluate_gen_attacks(reddit_pred_df['masked_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    known_conc_eval  = evaluate_gen_attacks(reddit_pred_df['known_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    bart_conc_eval   = evaluate_gen_attacks(reddit_pred_df['bart_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    arglex_conc_eval = evaluate_gen_attacks(reddit_pred_df['arglex_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    pred_conc_eval   = evaluate_gen_attacks(reddit_pred_df['joint_conc_baseline_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    joint_conc_eval  = evaluate_gen_attacks(reddit_pred_df['joint_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    \n",
    "    #Test stance correctness\n",
    "    filtered_reddit_pred_df = reddit_pred_df[pd.notna(reddit_pred_df.conclusion_target)]\n",
    "    \n",
    "    \n",
    "    #compute the stance of the generated counters towards the conclusion target\n",
    "    filtered_reddit_pred_df['masked_conc_stances'] = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.masked_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['known_conc_stances']  = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.known_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['bart_conc_stances']   = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.bart_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['arglex_conc_stances'] = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.arglex_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['pred_conc_stances']   = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.joint_conc_baseline_attacks.tolist())\n",
    "    filtered_reddit_pred_df['joint_conc_stances']  = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.joint_conc_attacks.tolist())\n",
    "    \n",
    "    #compute the distance between the conclusion stance and the attack stance: the bigger the distance the better...\n",
    "    masked_conc_eval['stance_score'] = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.masked_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    known_conc_eval['stance_score']  = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.known_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    bart_conc_eval['stance_score']   = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.bart_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    arglex_conc_eval['stance_score'] = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.arglex_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    pred_conc_eval['stance_score']   = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.pred_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    joint_conc_eval['stance_score']  = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.joint_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "\n",
    "    #check if the two stances are contradicotry\n",
    "    #masked_conc_stance_score2 = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.masked_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #known_conc_stance_score2  = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.known_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #bart_conc_stance_score2   = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.bart_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #pred_conc_stance_score2  = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.pred_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #joint_conc_stance_score2  = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.joint_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    return {'Masked Conclusion': masked_conc_eval,\n",
    "            'BART Conclusion': bart_conc_eval,\n",
    "            'ArgLexRank Conclusion': arglex_conc_eval,\n",
    "            'Joint Prediction (baseline)': pred_conc_eval,\n",
    "            'Joint Prediction': joint_conc_eval,\n",
    "            'Known Conclusion': known_conc_eval,\n",
    "            'preds_df' : reddit_pred_df,\n",
    "            'stances_df': filtered_reddit_pred_df}\n",
    "\n",
    "\n",
    "def print_results(pred_df_scores):\n",
    "    print(tabulate([['Masked Conclusion'] + [pred_df_scores['Masked Conclusion']['bleu'], pred_df_scores['Masked Conclusion']['bert-fscore'], pred_df_scores['Masked Conclusion']['stance_score']],\n",
    "                    ['BART Conclusion'] + [pred_df_scores['BART Conclusion']['bleu'], pred_df_scores['BART Conclusion']['bert-fscore'], pred_df_scores['BART Conclusion']['stance_score']],\n",
    "                    ['ArgLexRank Conclusion'] + [pred_df_scores['ArgLexRank Conclusion']['bleu'], pred_df_scores['ArgLexRank Conclusion']['bert-fscore'], pred_df_scores['ArgLexRank Conclusion']['stance_score']],\n",
    "                    ['Joint Prediction (baseline)'] + [pred_df_scores['Joint Prediction (baseline)']['bleu'], pred_df_scores['Joint Prediction (baseline)']['bert-fscore'], pred_df_scores['Joint Prediction (baseline)']['stance_score']],\n",
    "                    ['Joint Prediction'] + [pred_df_scores['Joint Prediction']['bleu'], pred_df_scores['Joint Prediction']['bert-fscore'], pred_df_scores['Joint Prediction']['stance_score']],\n",
    "                    ['Known Conclusion'] + [pred_df_scores['Known Conclusion']['bleu'], pred_df_scores['Known Conclusion']['bert-fscore'], pred_df_scores['Known Conclusion']['stance_score']],\n",
    "        ], headers=['bleu', 'bert-f1score', 'stance-score (diff)']))\n",
    "\n",
    "    print('=======')\n",
    "    #Check significancy:\n",
    "    print('BART vs baseline (BLEU):', check_sig(pred_df_scores['Joint Prediction']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores']))\n",
    "    print('BART vs baseline (BERT):', check_sig(pred_df_scores['Joint Prediction']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores']))\n",
    "    print('-------')\n",
    "    print('Joint Prediction (baseline) vs baseline (BLEU):', check_sig(pred_df_scores['Joint Prediction (baseline)']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores']))\n",
    "    print('Joint Prediction (baseline) vs baseline (BERT):', check_sig(pred_df_scores['Joint Prediction (baseline)']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores']))\n",
    "    print('-------')\n",
    "    print('Joint Prediction vs baseline (BLEU):', check_sig(pred_df_scores['Joint Prediction']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores']))\n",
    "    print('Joint Prediction vs baseline (BERT):', check_sig(pred_df_scores['Joint Prediction']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores']))\n",
    "    print('-------')\n",
    "    print('Known Conclusion vs baseline (BLEU):', check_sig(pred_df_scores['Known Conclusion']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores']))\n",
    "    print('Known Conclusion vs baseline (BERT):', check_sig(pred_df_scores['Known Conclusion']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models trained on all data for different levels of conclusion masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique_path = '/reddit_data/conclusion_and_ca_generation/valid_conclusion_all_sample_with_targets_with_arglexrank_conclusions.pkl'\n",
    "data_path = '/reddit_data/conclusion_and_ca_generation/valid_conclusion_all.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Reddit models\n",
    "known_conclusion_model = BartForConditionalGeneration.from_pretrained(local_home_dir  + '/output/valid-ft-all/known-conc-model-2e-05-32').to(device)\n",
    "known_conclusion_tokenizer = BartTokenizer.from_pretrained(local_home_dir + '/output/valid-ft-all/known-conc-model-2e-05-32')\n",
    "\n",
    "pred_conclusion_model = BartForConditionalGeneration.from_pretrained(local_home_dir  + '/output/valid-ft-all/pred-conc-model-2e-05-32/').to(device)\n",
    "pred_conclusion_tokenizer = BartTokenizer.from_pretrained(local_home_dir + '/output/valid-ft-all/pred-conc-model-2e-05-32/')\n",
    "\n",
    "join_model_tokenizer = BartTokenizer.from_pretrained('../data/output/valid-ft-all/mt-model-5e-05-32/checkpoint-7500/')\n",
    "join_model  = BartModelV2.from_pretrained('../data/output/valid-ft-all/mt-model-5e-05-32/checkpoint-7500/', compute_dynamic_weights=True, conc_decoder=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_pickle(ceph_dir + data_unique_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_of_masking = [1.0, 0.75, 0.6, 0.5]\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"do_sample\": False, \n",
    "    \"max_length\":100,\n",
    "    \"num_beams\":10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcea714622b34fd09ac0b8d97d4e1a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05f9d030f1d4c449b66197c7c3eaec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3dba23ddcf4b17b779247289bcb828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b86ad7987ec4198ac336a287e3ef40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a98cdfb1e634acabe800ec8c25b7bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_pred_scores = []\n",
    "for lvl in levels_of_masking:\n",
    "    masked_clm = '{}_perc_masked_premises'.format(lvl*10)\n",
    "    valid_df = remove_similar_sents(valid_df, threshold=lvl, masked_clm = masked_clm)\n",
    "\n",
    "    #Create a dataset\n",
    "    unique_valid_posts = valid_df.drop_duplicates('post_id')\n",
    "    valid_ds = Dataset.from_pandas(unique_valid_posts)\n",
    "    #If we want to take a small sample..\n",
    "    #valid_ds = valid_ds.train_test_split(0.5)\n",
    "    #valid_ds = valid_ds['test']\n",
    "    valid_ds = valid_ds.flatten_indices()\n",
    "\n",
    "    #generate predictions\n",
    "    reddit_pred_df = create_predictions_df(valid_ds, gen_kwargs, premises_clm=masked_clm)\n",
    "    reddit_pred_df.to_pickle('../data/output/reddit_pred_df_{}.pkl'.format(masked_clm))\n",
    "    \n",
    "    pred_df_scores = get_evaluation_results(reddit_pred_df, ceph_dir + data_path)\n",
    "    print_results(pred_df_scores)\n",
    "    all_pred_scores.append(pred_df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate performance on different level of argument-lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit_pred_df = pd.read_pickle('../data/output/reddit_all_data_masked_premises_pred_df-nosample-beamsize-4.pkl')\n",
    "reddit_pred_df = pd.read_pickle('../data/output/reddit_all_data_pred_df-nosample-beamsize-4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_pred_df['arg_len'] = reddit_pred_df.premises.apply(lambda x: len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=1266, minmax=(69, 3980), mean=371.4462875197472, variance=94355.3065988548, skewness=3.6248924595462295, kurtosis=25.435689418974672)\n",
      "Median: 120.0\n"
     ]
    }
   ],
   "source": [
    "arg_len_dist = reddit_pred_df.arg_len.tolist()\n",
    "plt.hist(arg_len_dist)\n",
    "plt.show()\n",
    "print(stats.describe(arg_len_dist))\n",
    "print('Median:', stats.median_abs_deviation(arg_len_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of arguments longer than the median: 84\n",
      "Num of arguments shorter than the median: 1181\n"
     ]
    }
   ],
   "source": [
    "print('Num of arguments longer than the median:', len([x for x in arg_len_dist if x < 120]))\n",
    "print('Num of arguments shorter than the median:', len([x for x in arg_len_dist if x > 120]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient: 100%|██████████| 1198/1198 [1:55:35<00:00,  5.79s/it]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "ProConClient: 100%|██████████| 83/83 [00:00<00:00, 157.96it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "ProConClient:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 83/83 [00:06<00:00, 12.15it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "\n",
      "ProConClient: 100%|██████████| 83/83 [00:11<00:00, 157.96it/s]\n",
      "\n",
      "ProConClient: 100%|██████████| 83/83 [00:05<00:00, 15.93it/s]\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "\n",
      "\n",
      "ProConClient:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ProConClient: 100%|██████████| 83/83 [00:06<00:00, 13.78it/s]\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ProConClient:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "ProConClient: 100%|██████████| 83/83 [00:19<00:00, 12.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ProConClient: 100%|██████████| 83/83 [00:06<00:00, 13.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ProConClient:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ProConClient: 100%|██████████| 83/83 [00:17<00:00, 13.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "ProConClient: 100%|██████████| 83/83 [00:22<00:00, 15.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ProConClient: 100%|██████████| 83/83 [00:06<00:00, 13.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ProConClient: 100%|██████████| 83/83 [00:30<00:00,  2.70it/s] \n",
      "ProConClient: 100%|██████████| 83/83 [00:30<00:00,  2.75it/s]\n",
      "ProConClient: 100%|██████████| 83/83 [00:23<00:00,  3.55it/s]\n",
      "ProConClient: 100%|██████████| 83/83 [00:18<00:00,  4.57it/s]\n",
      "ProConClient: 100%|██████████| 83/83 [00:12<00:00,  6.84it/s]\n",
      "ProConClient: 100%|██████████| 83/83 [00:06<00:00, 13.60it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:14<00:00, 58.29it/s] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:14<00:00, 77.15it/s]\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:16<00:00, 57.53it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "ProConClient:   0%|          | 0/1115 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient:  45%|████▍     | 500/1115 [00:06<00:07, 81.19it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:32<00:00, 57.53it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:18<00:00, 54.05it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "\n",
      "ProConClient:   0%|          | 0/1115 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "ProConClient:  45%|████▍     | 500/1115 [00:12<00:15, 39.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "ProConClient:  90%|████████▉ | 1000/1115 [00:13<00:01, 88.18it/s]\u001b[A\u001b[A\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:36<00:00, 54.05it/s]\u001b[A\n",
      "\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:19<00:00, 56.11it/s]\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:53<00:00, 20.70it/s]\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:37<00:00, 29.82it/s]\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:19<00:00, 57.74it/s]\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:18<00:00, 54.05it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "ProConClient:   0%|          | 0/1115 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:29<00:00, 54.05it/s][A\n",
      "ProConClient:  90%|████████▉ | 1000/1115 [00:12<00:01, 83.91it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:19<00:00, 47.97it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "short_arg_pred_df_scores = get_evaluation_results(reddit_pred_df[reddit_pred_df.arg_len <= 120],  ceph_dir + '/reddit_data/conclusion_and_ca_generation/valid_conclusion_comp_remove_75sem_perc.pkl')\n",
    "long_arg_pred_df_scores = get_evaluation_results(reddit_pred_df[reddit_pred_df.arg_len > 120],  ceph_dir + '/reddit_data/conclusion_and_ca_generation/valid_conclusion_comp_remove_75sem_perc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  --------  --------------  ---------------------\n",
      "Masked Conclusion            0.182676        0.160757                   0.85\n",
      "BART Conclusion              0.239127        0.203622                   0.82\n",
      "ArgLexRank Conclusion        0.17765         0.149343                   0.78\n",
      "Joint Prediction (baseline)  0.175237        0.169731                   0.7\n",
      "Joint Prediction             0.25985         0.199717                   0.82\n",
      "Known Conclusion             0.264454        0.208966                   0.7\n",
      "=======\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BLEU): False\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BERT): True\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction (baseline) vs baseline (BLEU): False\n",
      "Distribution is normal, so using ttest_rel\n",
      "Joint Prediction (baseline) vs baseline (BERT): False\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BLEU): False\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BERT): True\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BLEU): False\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BERT): True\n"
     ]
    }
   ],
   "source": [
    "print_results(short_arg_pred_df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  --------  --------------  ---------------------\n",
      "Masked Conclusion            0.151293        0.137899                   0.74\n",
      "BART Conclusion              0.168714        0.178853                   0.69\n",
      "ArgLexRank Conclusion        0.137489        0.127679                   0.77\n",
      "Joint Prediction (baseline)  0.161659        0.160567                   0.77\n",
      "Joint Prediction             0.186468        0.150083                   0.78\n",
      "Known Conclusion             0.201845        0.179771                   0.66\n",
      "=======\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BERT): False\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction (baseline) vs baseline (BLEU): False\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction (baseline) vs baseline (BERT): True\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BERT): False\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BERT): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ProConClient: 100%|██████████| 1115/1115 [00:31<00:00, 47.97it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "print_results(long_arg_pred_df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
