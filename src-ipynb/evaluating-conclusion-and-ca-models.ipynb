{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from argparse import Namespace\n",
    "\n",
    "sys.path.append('../src-py/')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from utils import *\n",
    "from project_debater_api import *\n",
    "from mt_bart_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceph_dir = '/home/sile2804/data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation'\n",
    "local_home_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_attacks(ds, model, tokenizer, premises_clm, conclusion_clm, gen_kwargs, skip_special_tokens=True, batch_size=16):\n",
    "    ds = ds.map(lambda x :preprocess_function(x, tokenizer, premises_clm, 'counter', conclusion_clm=conclusion_clm), batched=True)\n",
    "    ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    dataloader = torch.utils.data.DataLoader(ds, batch_size=batch_size)\n",
    "    attacks = generate_counters(model, tokenizer, dataloader, gen_kwargs, skip_special_tokens=skip_special_tokens)\n",
    "    \n",
    "    return attacks\n",
    "\n",
    "def create_predictions_df(reddit_sample_valid_ds, gen_kwargs, premises_clm='masked_premises'):\n",
    "    \n",
    "    joint_attacks       = generate_ds_attacks(reddit_sample_valid_ds, join_model, join_model_tokenizer, premises_clm, None, gen_kwargs)\n",
    "    known_conc_attacks  = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, 'title', gen_kwargs)\n",
    "    bart_conc_attacks   = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, 'bart_conclusion', gen_kwargs)\n",
    "    arglex_conc_attacks = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, 'arglex_rank_conclusion', gen_kwargs)\n",
    "    masked_conc_attacks = generate_ds_attacks(reddit_sample_valid_ds, known_conclusion_model, known_conclusion_tokenizer, premises_clm, None, gen_kwargs)\n",
    "    \n",
    "    #update max_gen_length to account to the generated conclusion\n",
    "    gen_kwargs['max_length'] = gen_kwargs['max_length'] + 30\n",
    "    joint_conc_baseline_attacks  = generate_ds_attacks(reddit_sample_valid_ds, pred_conclusion_model, pred_conclusion_tokenizer, premises_clm, None, gen_kwargs, skip_special_tokens=False)\n",
    "    #This model would predict the conclusion and then the counter in one sequence.\n",
    "\n",
    "    reddit_pred_df = pd.DataFrame(list(zip(\n",
    "                                           reddit_sample_valid_ds['post_id'],\n",
    "                                           reddit_sample_valid_ds['title'], \n",
    "                                           reddit_sample_valid_ds['conclusion_targets'],\n",
    "                                           reddit_sample_valid_ds['conclusion_stance'],\n",
    "                                           reddit_sample_valid_ds['bart_conclusion'], \n",
    "                                           reddit_sample_valid_ds['arglex_rank_conclusion'], \n",
    "                                           reddit_sample_valid_ds[premises_clm],\n",
    "                                           reddit_sample_valid_ds['counter'], \n",
    "                                           known_conc_attacks, masked_conc_attacks, \n",
    "                                           bart_conc_attacks, arglex_conc_attacks, joint_attacks, joint_conc_baseline_attacks)), \n",
    "                    columns=['post_id', 'conclusion', 'conclusion_target', 'conclusion_stance', 'bart_conclusion', 'arglex_rank_conclusion', 'premises', 'gt_attack', 'known_conc_attacks', \n",
    "                             'masked_conc_attacks', 'bart_conc_attacks', 'arglex_conc_attacks', 'joint_conc_attacks', 'joint_conc_baseline_attacks'])\n",
    "\n",
    "    reddit_pred_df['argument'] = reddit_pred_df.apply(lambda row: row['conclusion'] + ' : ' + ' '.join(row['premises']), axis=1)\n",
    "    reddit_pred_df['premises'] = reddit_pred_df['premises'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    #process the jointly generated conclusion and counter\n",
    "    reddit_pred_df['joint_conc_baseline'] = reddit_pred_df['joint_conc_baseline_attacks'].apply (lambda x: x.split('<counter>')[0])\n",
    "    reddit_pred_df['joint_conc_baseline_attacks'] = reddit_pred_df['joint_conc_baseline_attacks'].apply (lambda x: x.split('<counter>')[1] if '<counter>' in x else x)\n",
    "    reddit_pred_df['joint_conc_baseline'] = reddit_pred_df['joint_conc_baseline'].apply (lambda x: re.sub('<s>|</s>|<conclusion>|<counter>|<pad>', '', x).strip())\n",
    "    reddit_pred_df['joint_conc_baseline_attacks'] = reddit_pred_df['joint_conc_baseline_attacks'].apply (lambda x: re.sub('<s>|</s>|<conclusion>|<counter>|<pad>', '', x).strip())\n",
    "\n",
    "    return reddit_pred_df\n",
    "\n",
    "def get_evaluation_results(reddit_pred_df, df_path):\n",
    "    \n",
    "    #collect references\n",
    "    df = pd.read_pickle(df_path)\n",
    "    arg_counters = df.groupby('post_id').agg({\n",
    "        'counter': lambda x: [' '.join(c) for c in x]\n",
    "    }).reset_index()\n",
    "\n",
    "    arg_counters = pd.Series(arg_counters.counter.values, index=arg_counters.post_id).to_dict()\n",
    "\n",
    "    reddit_pred_df['all_counters'] = reddit_pred_df['post_id'].apply(lambda x: arg_counters[x])\n",
    "    reddit_pred_df['all_counters'] = reddit_pred_df.all_counters.apply(lambda claims: [c for c in claims if c !=''])\n",
    "    reddit_pred_df = reddit_pred_df[reddit_pred_df.all_counters.map(len) > 0]\n",
    "\n",
    "    masked_conc_eval = evaluate_gen_attacks(reddit_pred_df['masked_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    known_conc_eval  = evaluate_gen_attacks(reddit_pred_df['known_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    bart_conc_eval   = evaluate_gen_attacks(reddit_pred_df['bart_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    arglex_conc_eval = evaluate_gen_attacks(reddit_pred_df['arglex_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    pred_conc_eval   = evaluate_gen_attacks(reddit_pred_df['joint_conc_baseline_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    joint_conc_eval  = evaluate_gen_attacks(reddit_pred_df['joint_conc_attacks'].tolist(), reddit_pred_df['all_counters'].tolist(), detailed=True)\n",
    "    \n",
    "    #Test stance correctness\n",
    "    filtered_reddit_pred_df = reddit_pred_df[pd.notna(reddit_pred_df.conclusion_target)]\n",
    "    \n",
    "    \n",
    "    #compute the stance of the generated counters towards the conclusion target\n",
    "    filtered_reddit_pred_df['masked_conc_stances'] = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.masked_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['known_conc_stances']  = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.known_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['bart_conc_stances']   = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.bart_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['arglex_conc_stances'] = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.arglex_conc_attacks.tolist())\n",
    "    filtered_reddit_pred_df['pred_conc_stances']   = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.joint_conc_baseline_attacks.tolist())\n",
    "    filtered_reddit_pred_df['joint_conc_stances']  = get_stances(filtered_reddit_pred_df.conclusion_target.tolist(), filtered_reddit_pred_df.joint_conc_attacks.tolist())\n",
    "    \n",
    "    #compute the distance between the conclusion stance and the attack stance: the bigger the distance the better...\n",
    "    masked_conc_eval['stance_score'] = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.masked_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    known_conc_eval['stance_score']  = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.known_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    bart_conc_eval['stance_score']   = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.bart_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    arglex_conc_eval['stance_score'] = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.arglex_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    pred_conc_eval['stance_score']   = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.pred_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "    joint_conc_eval['stance_score']  = round(np.mean([abs(x[0] - x[1]) for x in zip(filtered_reddit_pred_df.joint_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())]), 2)\n",
    "\n",
    "    #check if the two stances are contradicotry\n",
    "    #masked_conc_stance_score2 = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.masked_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #known_conc_stance_score2  = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.known_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #bart_conc_stance_score2   = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.bart_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #pred_conc_stance_score2  = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.pred_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    #joint_conc_stance_score2  = round(sum([int(x[0] * x[1] < 0) for x in zip(filtered_reddit_pred_df.joint_conc_stances.tolist(), filtered_reddit_pred_df.conclusion_stance.tolist())])/len(filtered_reddit_pred_df), 2)\n",
    "    return {'Masked Conclusion': masked_conc_eval,\n",
    "            'BART Conclusion': bart_conc_eval,\n",
    "            'ArgLexRank Conclusion': arglex_conc_eval,\n",
    "            'Joint Prediction (baseline)': pred_conc_eval,\n",
    "            'Joint Prediction': joint_conc_eval,\n",
    "            'Known Conclusion': known_conc_eval,\n",
    "            'preds_df' : reddit_pred_df,\n",
    "            'stances_df': filtered_reddit_pred_df}\n",
    "\n",
    "\n",
    "def print_results(pred_df_scores, print_sig=False, sig_lvl=0.05):\n",
    "    for key in ['Masked Conclusion', 'BART Conclusion', 'ArgLexRank Conclusion', 'Joint Prediction (baseline)', 'Joint Prediction', 'Known Conclusion']:\n",
    "        for key2 in ['bleu', 'bert-fscore']:\n",
    "            pred_df_scores[key][key2] = round(pred_df_scores[key][key2], 2)\n",
    "            \n",
    "    res_table = tabulate([['Masked Conclusion'] + [pred_df_scores['Masked Conclusion']['bleu'], pred_df_scores['Masked Conclusion']['bert-fscore'], pred_df_scores['Masked Conclusion']['stance_score']],\n",
    "                    ['BART Conclusion'] + [pred_df_scores['BART Conclusion']['bleu'], pred_df_scores['BART Conclusion']['bert-fscore'], pred_df_scores['BART Conclusion']['stance_score']],\n",
    "                    ['ArgLexRank Conclusion'] + [pred_df_scores['ArgLexRank Conclusion']['bleu'], pred_df_scores['ArgLexRank Conclusion']['bert-fscore'], pred_df_scores['ArgLexRank Conclusion']['stance_score']],\n",
    "                    ['Joint Prediction (baseline)'] + [pred_df_scores['Joint Prediction (baseline)']['bleu'], pred_df_scores['Joint Prediction (baseline)']['bert-fscore'], pred_df_scores['Joint Prediction (baseline)']['stance_score']],\n",
    "                    ['Joint Prediction'] + [pred_df_scores['Joint Prediction']['bleu'], pred_df_scores['Joint Prediction']['bert-fscore'], pred_df_scores['Joint Prediction']['stance_score']],\n",
    "                    ['Known Conclusion'] + [pred_df_scores['Known Conclusion']['bleu'], pred_df_scores['Known Conclusion']['bert-fscore'], pred_df_scores['Known Conclusion']['stance_score']],\n",
    "        ], headers=['bleu', 'bert-f1score', 'stance-score (diff)'])\n",
    "    \n",
    "    print(res_table)\n",
    "\n",
    "    if print_sig:\n",
    "        print('=======')\n",
    "        #Check significancy:\n",
    "        print('BART vs baseline (BLEU):', check_sig(pred_df_scores['Joint Prediction']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores'], alpha=sig_lvl))\n",
    "        print('BART vs baseline (BERT):', check_sig(pred_df_scores['Joint Prediction']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores'], alpha=sig_lvl))\n",
    "        print('-------')\n",
    "        print('Joint Prediction (baseline) vs baseline (BLEU):', check_sig(pred_df_scores['Joint Prediction (baseline)']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores'], alpha=sig_lvl))\n",
    "        print('Joint Prediction (baseline) vs baseline (BERT):', check_sig(pred_df_scores['Joint Prediction (baseline)']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores'], alpha=sig_lvl))\n",
    "        print('-------')\n",
    "        print('Joint Prediction vs baseline (BLEU):', check_sig(pred_df_scores['Joint Prediction']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores'], alpha=sig_lvl))\n",
    "        print('Joint Prediction vs baseline (BERT):', check_sig(pred_df_scores['Joint Prediction']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores'], alpha=sig_lvl))\n",
    "        print('-------')\n",
    "        print('Known Conclusion vs baseline (BLEU):', check_sig(pred_df_scores['Known Conclusion']['bleu_scores'], pred_df_scores['Masked Conclusion']['bleu_scores'], alpha=sig_lvl))\n",
    "        print('Known Conclusion vs baseline (BERT):', check_sig(pred_df_scores['Known Conclusion']['bert-fscores'], pred_df_scores['Masked Conclusion']['bert-fscores'], alpha=sig_lvl))\n",
    "        \n",
    "    return res_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models trained on all data for different levels of conclusion masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_unique_path = '/reddit_data/conclusion_and_ca_generation/valid_conclusion_all_sample_with_targets_with_arglexrank_conclusions.pkl'\n",
    "# data_path = '/reddit_data/conclusion_and_ca_generation/valid_conclusion_all.pkl'\n",
    "\n",
    "data_unique_path = '/reddit_data/conclusion_and_ca_generation/test_conclusion_all_sample_with_targets_with_arglexrank_conclusions.pkl'\n",
    "data_path = '/reddit_data/conclusion_and_ca_generation/test_concusion_all.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls ../../../data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation/reddit_data/conclusion_and_ca_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Reddit models\n",
    "known_conclusion_model = BartForConditionalGeneration.from_pretrained(local_home_dir  + '/output/valid-ft-all/known-conc-model-2e-05-32').to(device)\n",
    "known_conclusion_tokenizer = BartTokenizer.from_pretrained(local_home_dir + '/output/valid-ft-all/known-conc-model-2e-05-32')\n",
    "\n",
    "pred_conclusion_model = BartForConditionalGeneration.from_pretrained(local_home_dir  + '/output/valid-ft-all/pred-conc-model-2e-05-32/').to(device)\n",
    "pred_conclusion_tokenizer = BartTokenizer.from_pretrained(local_home_dir + '/output/valid-ft-all/pred-conc-model-2e-05-32/')\n",
    "\n",
    "join_model_tokenizer = BartTokenizer.from_pretrained('../data/output/valid-ft-all/mt-model-5e-05-32/checkpoint-7500/')\n",
    "join_model  = BartModelV2.from_pretrained('../data/output/valid-ft-all/mt-model-5e-05-32/checkpoint-7500/', compute_dynamic_weights=True, conc_decoder=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_pickle(ceph_dir + data_unique_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1901 posts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a68eb2e628f4b26884035c16feb97a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115c7a8cb3284a9394d27878caed4455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient:   0%|          | 0/20 [05:27<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f5716fe8b54beeada1514b52365490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc18fe4ba7940beaa132b4e6fc9ea47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d694df2e62340be910abd3ba3ac7c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddd ['as well, overdose due to drugs cut with unknown and dangerous substances and the spread of diseases through sharing needles is an epidemic that is a further tax on our healthcare system. by manufacturing these drugs and having them available for public consumption we could eliminate the spread of diseases, and prevent overdoses by controlling the whole process of drug addiction.', 'as a immigrant who spent thousands of dollars and many hours working to come legally i find it highly irritating that they re being defended for breaking a law. this political agenda people use only makes it worse for them.', 'sorry if this sounds sexist, but women and men are different, and i believe it is valid to be more or less jealous of people based on their character. it also seems to me that men are very strongly conditioned to be jealous of other men, while the same conditioning does not really happen for jealousy of women now, this can very well be because whatever forces gave rise to this conditioning were in some way sexist to the extent that abstract concepts can be sexist but that does not affect my point .']\n",
      "ddd ['i wouldn t want to house an unwanted guest either, but out of respect for your partner you should at least hear them out. you don t get one yes and one no in this sort of situation.', 'it should be obvious, but lest anyone attempt to shift the goalposts here i will explicitly state that this cmv does not include people who deliberately endeavor to assert their opposing beliefs for the purpose of belittling trans individuals. such behavior exhibits a lack of empathy and deserves every bit of criticism it receives.', 'if the teachers don t have enough time to prepare materials or grade homework themselves, maybe they shouldn t be teaching as many courses as they are, or they should get an intern to help with the grading. college is already expensive enough, and many students are struggling to make ends meet as it is.']\n"
     ]
    }
   ],
   "source": [
    "gen_kwargs = {\n",
    "    \"do_sample\": False, \n",
    "    \"max_length\":100,\n",
    "    \"num_beams\":10\n",
    "}\n",
    "\n",
    "#Create a dataset\n",
    "unique_valid_posts = valid_df.drop_duplicates('post_id')\n",
    "print('Testing on {} posts'.format(len(unique_valid_posts)))\n",
    "valid_ds = Dataset.from_pandas(unique_valid_posts)\n",
    "valid_ds = valid_ds.flatten_indices()\n",
    "\n",
    "#generate predictions\n",
    "reddit_pred_df = create_predictions_df(valid_ds, gen_kwargs, premises_clm='post')\n",
    "reddit_pred_df.to_pickle('../data/output/reddit_pred_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit_pred_df = pd.read_pickle('../data/output/reddit_pred_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is 1901 with average similarity to conclusion = 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient: 100%|██████████| 380/380 [11:31:46<00:00, 109.23s/it]\n",
      "ProConClient: 100%|██████████| 1901/1901 [00:18<00:00, 86.43it/s] \n",
      "ProConClient:   0%|          | 0/1901 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1901/1901 [00:29<00:00, 86.43it/s][A\n",
      "ProConClient:  53%|█████▎    | 1000/1901 [00:12<00:10, 82.96it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1901/1901 [00:43<00:00, 44.11it/s]\u001b[A\n",
      "\n",
      "ProConClient:  53%|█████▎    | 1000/1901 [00:12<00:10, 82.95it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1901/1901 [00:24<00:00, 78.85it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1901/1901 [00:24<00:00, 77.19it/s]\n",
      "\n",
      "ProConClient:   0%|          | 0/1901 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "ProConClient:  26%|██▋       | 500/1901 [00:06<00:16, 83.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "ProConClient:  53%|█████▎    | 1000/1901 [00:12<00:10, 82.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "ProConClient: 100%|██████████| 1901/1901 [00:48<00:00, 39.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ProConClient:  53%|█████▎    | 1000/1901 [00:12<00:10, 85.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "ProConClient: 100%|██████████| 1901/1901 [00:24<00:00, 77.26it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  ------  --------------  ---------------------\n",
      "Masked Conclusion              0.24            0.17                   0.77\n",
      "BART Conclusion                0.27            0.21                   0.7\n",
      "ArgLexRank Conclusion          0.21            0.16                   0.74\n",
      "Joint Prediction (baseline)    0.25            0.19                   0.75\n",
      "Joint Prediction               0.25            0.17                   0.76\n",
      "Known Conclusion               0.31            0.22                   0.61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'                               bleu    bert-f1score    stance-score (diff)\\n---------------------------  ------  --------------  ---------------------\\nMasked Conclusion              0.24            0.17                   0.77\\nBART Conclusion                0.27            0.21                   0.7\\nArgLexRank Conclusion          0.21            0.16                   0.74\\nJoint Prediction (baseline)    0.25            0.19                   0.75\\nJoint Prediction               0.25            0.17                   0.76\\nKnown Conclusion               0.31            0.22                   0.61'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of samples is {} with average similarity to conclusion = {}'.format(len(reddit_pred_df), round(reddit_pred_df['max_sim_to_conclusion'].mean(), 2)))\n",
    "pred_df_scores = get_evaluation_results(reddit_pred_df, ceph_dir + data_path)\n",
    "print_results(pred_df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze effectiveness for different levels of similarity to conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_pred_df = split_dataframe_per_conc_similarity(reddit_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe57c870d68>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reddit_pred_df['max_sim_to_conclusion'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is 380 with average similarity to conclusion = 0.4\n",
      "Number of samples is 380 with average similarity to conclusion = 0.53\n",
      "Number of samples is 380 with average similarity to conclusion = 0.6\n",
      "Number of samples is 380 with average similarity to conclusion = 0.67\n",
      "Number of samples is 380 with average similarity to conclusion = 0.75\n"
     ]
    }
   ],
   "source": [
    "#Analyze scores on different levels of similarity to conclusion\n",
    "sorted_df  = reddit_pred_df.sort_values('max_sim_to_conclusion')\n",
    "num_chunks = 5\n",
    "chunk_size = int(len(sorted_df)/num_chunks)\n",
    "all_pred_scores = []\n",
    "for i in range(0, num_chunks) :\n",
    "    reddit_pred_df_chunk = sorted_df[i*chunk_size: (i+1) * chunk_size].copy()\n",
    "    print('Number of samples is {} with average similarity to conclusion = {}'.format(len(reddit_pred_df_chunk), round(reddit_pred_df_chunk['max_sim_to_conclusion'].mean(), 2)))\n",
    "    pred_df_scores = get_evaluation_results(reddit_pred_df_chunk, ceph_dir + data_path)\n",
    "    print_results(pred_df_scores)\n",
    "    all_pred_scores.append(pred_df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(all_pred_scores[-1], open('../data/output/test_eval_results.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  ------  --------------  ---------------------\n",
      "Masked Conclusion              0.21            0.14                   0.78\n",
      "BART Conclusion                0.23            0.2                    0.72\n",
      "ArgLexRank Conclusion          0.2             0.14                   0.79\n",
      "Joint Prediction (baseline)    0.22            0.17                   0.72\n",
      "Joint Prediction               0.21            0.15                   0.77\n",
      "Known Conclusion               0.29            0.21                   0.62\n",
      "                               bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  ------  --------------  ---------------------\n",
      "Masked Conclusion              0.25            0.16                   0.8\n",
      "BART Conclusion                0.25            0.21                   0.74\n",
      "ArgLexRank Conclusion          0.21            0.15                   0.77\n",
      "Joint Prediction (baseline)    0.26            0.19                   0.78\n",
      "Joint Prediction               0.23            0.15                   0.77\n",
      "Known Conclusion               0.33            0.22                   0.68\n",
      "                               bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  ------  --------------  ---------------------\n",
      "Masked Conclusion              0.23            0.17                   0.78\n",
      "BART Conclusion                0.27            0.21                   0.67\n",
      "ArgLexRank Conclusion          0.19            0.15                   0.74\n",
      "Joint Prediction (baseline)    0.24            0.19                   0.75\n",
      "Joint Prediction               0.25            0.16                   0.77\n",
      "Known Conclusion               0.31            0.22                   0.58\n",
      "                               bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  ------  --------------  ---------------------\n",
      "Masked Conclusion              0.24            0.18                   0.77\n",
      "BART Conclusion                0.27            0.22                   0.67\n",
      "ArgLexRank Conclusion          0.22            0.17                   0.7\n",
      "Joint Prediction (baseline)    0.25            0.2                    0.74\n",
      "Joint Prediction               0.27            0.18                   0.73\n",
      "Known Conclusion               0.32            0.23                   0.6\n",
      "                               bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  ------  --------------  ---------------------\n",
      "Masked Conclusion              0.26            0.19                   0.72\n",
      "BART Conclusion                0.31            0.23                   0.7\n",
      "ArgLexRank Conclusion          0.23            0.18                   0.73\n",
      "Joint Prediction (baseline)    0.27            0.21                   0.73\n",
      "Joint Prediction               0.28            0.2                    0.78\n",
      "Known Conclusion               0.32            0.22                   0.6\n"
     ]
    }
   ],
   "source": [
    "for s in all_pred_scores:\n",
    "    x = print_results(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze effectiveness for different levels of argument length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_pred_df['arg_len'] = reddit_pred_df.premises.apply(lambda x: len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe773bc6860>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reddit_pred_df['arg_len'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze scores on different levels of argument length\n",
    "sorted_df  = reddit_pred_df.sort_values('arg_len')\n",
    "num_chunks = 5\n",
    "chunk_size = int(len(sorted_df)/num_chunks)\n",
    "all_pred_scores_per_len = []\n",
    "for i in range(1, num_chunks) :\n",
    "    reddit_pred_df_chunk = sorted_df[i*chunk_size: (i+1) * chunk_size].copy()\n",
    "    print('Number of samples is {} with average similarity to conclusion = {}'.format(len(reddit_pred_df_chunk), round(reddit_pred_df_chunk['arg_len'].mean(), 2)))\n",
    "    pred_df_scores = get_evaluation_results(reddit_pred_df_chunk, ceph_dir + data_path)\n",
    "    print_results(pred_df_scores)\n",
    "    all_pred_scores_per_len.append(pred_df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient: 100%|██████████| 1901/1901 [00:34<00:00, 77.26it/s]"
     ]
    }
   ],
   "source": [
    "for s in all_pred_scores_per_len:\n",
    "    print_results(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments by removing premises that are similar to the conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcea714622b34fd09ac0b8d97d4e1a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05f9d030f1d4c449b66197c7c3eaec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3dba23ddcf4b17b779247289bcb828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b86ad7987ec4198ac336a287e3ef40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a98cdfb1e634acabe800ec8c25b7bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dea89a1cf647e98eee4bb6e46b504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f51fc50c3a49b79330db2fb21966bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:26<00:00, 57.36it/s]\n",
      "ProConClient:   0%|          | 0/1499 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:37<00:00, 57.36it/s][A\n",
      "ProConClient:  67%|██████▋   | 1000/1499 [00:16<00:08, 59.95it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:51<00:00, 29.17it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:25<00:00, 59.65it/s]\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:24<00:00, 61.75it/s]\n",
      "ProConClient:   0%|          | 0/1499 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:36<00:00, 61.75it/s][A\n",
      "ProConClient:  67%|██████▋   | 1000/1499 [00:17<00:08, 56.58it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:50<00:00, 29.66it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:26<00:00, 57.47it/s]\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:25<00:00, 58.61it/s]\n",
      "ProConClient:   0%|          | 0/1499 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:35<00:00, 58.61it/s][A\n",
      "ProConClient:  67%|██████▋   | 1000/1499 [00:17<00:08, 56.42it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:26<00:00, 56.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  --------  --------------  ---------------------\n",
      "Masked Conclusion            0.133543        0.117534                   0.74\n",
      "BART Conclusion              0.136626        0.166914                   0.89\n",
      "ArgLexRank Conclusion        0.127403        0.120435                   0.77\n",
      "Joint Prediction (baseline)  0.143528        0.140205                   0.81\n",
      "Joint Prediction             0.152893        0.119865                   0.73\n",
      "Known Conclusion             0.196081        0.167839                   0.87\n",
      "=======\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BERT): False\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction (baseline) vs baseline (BLEU): False\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction (baseline) vs baseline (BERT): True\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BERT): False\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BERT): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient: 100%|██████████| 1499/1499 [00:59<00:00, 25.13it/s]\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:34<00:00, 43.94it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faa0ef9d06f431ebb7fb17b631d94ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34344d22c1b74c7294986423836c852b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a203794b19d44e5ab0f21c854f573445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3d5af445634a71aa6375ee5b35c844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca86e2354f644311a5aa94871b3fedd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80bd7af4d2f48318e3127466f6dab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d3d5684b9141ae9f58554fba59af84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:25<00:00, 57.55it/s]\n",
      "ProConClient:   0%|          | 0/1499 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient:  33%|███▎      | 500/1499 [00:05<00:10, 97.78it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:43<00:00, 57.55it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:46<00:00, 32.08it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:20<00:00, 72.29it/s]\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:20<00:00, 66.73it/s] \n",
      "ProConClient:   0%|          | 0/1499 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient:  33%|███▎      | 500/1499 [00:08<00:17, 57.76it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:36<00:00, 66.73it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:43<00:00, 34.36it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:23<00:00, 64.05it/s]\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:22<00:00, 68.06it/s]\n",
      "ProConClient:   0%|          | 0/1499 [00:00<?, ?it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:33<00:00, 68.06it/s][A\n",
      "ProConClient:  67%|██████▋   | 1000/1499 [00:15<00:07, 66.08it/s]\u001b[A\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:22<00:00, 69.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 bleu    bert-f1score    stance-score (diff)\n",
      "---------------------------  --------  --------------  ---------------------\n",
      "Masked Conclusion            0.126556        0.109075                   0.76\n",
      "BART Conclusion              0.134031        0.167167                   0.89\n",
      "ArgLexRank Conclusion        0.127082        0.11991                    0.78\n",
      "Joint Prediction (baseline)  0.139894        0.129912                   0.82\n",
      "Joint Prediction             0.139065        0.109321                   0.72\n",
      "Known Conclusion             0.19497         0.167571                   0.88\n",
      "=======\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "BART vs baseline (BERT): False\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction (baseline) vs baseline (BLEU): False\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction (baseline) vs baseline (BERT): True\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Joint Prediction vs baseline (BERT): False\n",
      "-------\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BLEU): True\n",
      "Distribution is not normal, so using wilcoxon\n",
      "Known Conclusion vs baseline (BERT): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ProConClient: 100%|██████████| 1499/1499 [00:40<00:00, 69.14it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "levels_of_masking = [1.0, 0.75, 0.6, 0.5]\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"do_sample\": False, \n",
    "    \"max_length\":100,\n",
    "    \"num_beams\":10\n",
    "}\n",
    "\n",
    "all_pred_scores = []\n",
    "for lvl in levels_of_masking:\n",
    "    masked_clm = '{}_perc_masked_premises'.format(lvl*10)\n",
    "    valid_df = remove_similar_sents(valid_df, threshold=lvl, masked_clm = masked_clm)\n",
    "\n",
    "    #Create a dataset\n",
    "    unique_valid_posts = valid_df.drop_duplicates('post_id')\n",
    "    valid_ds = Dataset.from_pandas(unique_valid_posts)\n",
    "    #If we want to take a small sample..\n",
    "    #valid_ds = valid_ds.train_test_split(0.5)\n",
    "    #valid_ds = valid_ds['test']\n",
    "    valid_ds = valid_ds.flatten_indices()\n",
    "\n",
    "    #generate predictions\n",
    "    reddit_pred_df = create_predictions_df(valid_ds, gen_kwargs, premises_clm=masked_clm)\n",
    "    reddit_pred_df.to_pickle('../data/output/reddit_pred_df_{}.pkl'.format(masked_clm))\n",
    "    \n",
    "    pred_df_scores = get_evaluation_results(reddit_pred_df, ceph_dir + data_path)\n",
    "    print_results(pred_df_scores)\n",
    "    all_pred_scores.append(pred_df_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
