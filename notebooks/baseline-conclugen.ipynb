{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/model_predictions.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conclusion             523\n",
       "premises               523\n",
       "argument               523\n",
       "auto_conc              523\n",
       "gt                     523\n",
       "masked_conc_attacks    523\n",
       "known_conc_attacks     523\n",
       "auto_conc_attacks      523\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gt']!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conclusion             522\n",
       "premises               522\n",
       "argument               522\n",
       "auto_conc              522\n",
       "gt                     522\n",
       "masked_conc_attacks    522\n",
       "known_conc_attacks     522\n",
       "auto_conc_attacks      522\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_conc_attacks = df['known_conc_attacks'].tolist()\n",
    "masked_conc_attacks = df['masked_conc_attacks'].tolist()\n",
    "auto_conc_attacks = df['auto_conc_attacks'].tolist()\n",
    "refs = df['gt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "premises = df['argument'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data_cg/references.txt\",\"w\", encoding='utf-8') as outf:\n",
    "    for line in refs:\n",
    "        outf.write(line)\n",
    "        outf.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/conclugen-bart-large-all/\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"../models/conclugen-bart-large-all/\")\n",
    "conclugen_pipeline = pipeline(\"summarization\", tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/model_predictions.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text, remove_extra_tokens=0):\n",
    "        for i in range(3):\n",
    "            tokens = tokenizer(\n",
    "                text, return_tensors=\"pt\", truncation=True\n",
    "            ).input_ids\n",
    "            max_model_length = tokens.size()[1]\n",
    "            truncated_tokens = tokens[0][: max_model_length - remove_extra_tokens]\n",
    "            text = tokenizer.decode(\n",
    "                truncated_tokens, clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            without_truncate_length = tokenizer(\n",
    "                text, return_tensors=\"pt\"\n",
    "            ).input_ids.size()[1]\n",
    "            if max_model_length > without_truncate_length:\n",
    "                return tokens, text\n",
    "        return truncate_text(text, remove_extra_tokens=remove_extra_tokens + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conclusion(row):\n",
    "    premises = row['premises']\n",
    "    tokens, processed_premises = truncate_text(premises)\n",
    "    conclugen = conclugen_pipeline(processed_premises, clean_up_tokenization_spaces=True)\n",
    "    conclusion = conclugen[0]['summary_text']\n",
    "    row['baseline_conclugen'] = conclusion.strip()\n",
    "    return row\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/523 [01:03<36:17,  4.30s/it]Your max_length is set to 62, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "  4%|▍         | 23/523 [01:28<32:24,  3.89s/it]Your max_length is set to 62, but you input_length is only 42. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "  6%|▌         | 29/523 [01:59<42:39,  5.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "  6%|▌         | 32/523 [02:20<48:14,  5.90s/it]Your max_length is set to 62, but you input_length is only 43. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "  8%|▊         | 44/523 [03:17<43:10,  5.41s/it]Your max_length is set to 62, but you input_length is only 9. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 10%|▉         | 50/523 [03:35<28:10,  3.57s/it]Your max_length is set to 62, but you input_length is only 49. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 14%|█▎        | 71/523 [05:02<30:21,  4.03s/it]Your max_length is set to 62, but you input_length is only 18. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 14%|█▍        | 72/523 [05:04<25:34,  3.40s/it]Your max_length is set to 62, but you input_length is only 53. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 15%|█▍        | 77/523 [05:30<39:07,  5.26s/it]Your max_length is set to 62, but you input_length is only 47. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 15%|█▍        | 78/523 [05:32<32:36,  4.40s/it]Your max_length is set to 62, but you input_length is only 49. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 15%|█▌        | 80/523 [05:41<33:22,  4.52s/it]Your max_length is set to 62, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 17%|█▋        | 88/523 [06:14<30:13,  4.17s/it]Your max_length is set to 62, but you input_length is only 41. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 18%|█▊        | 92/523 [06:30<32:38,  4.54s/it]Your max_length is set to 62, but you input_length is only 34. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 22%|██▏       | 115/523 [08:02<27:02,  3.98s/it]Your max_length is set to 62, but you input_length is only 52. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 23%|██▎       | 122/523 [08:30<27:46,  4.16s/it]Your max_length is set to 62, but you input_length is only 61. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 24%|██▍       | 125/523 [08:40<25:46,  3.89s/it]Your max_length is set to 62, but you input_length is only 47. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 25%|██▌       | 131/523 [09:03<25:29,  3.90s/it]Your max_length is set to 62, but you input_length is only 57. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 25%|██▌       | 133/523 [09:08<21:42,  3.34s/it]Your max_length is set to 62, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 27%|██▋       | 143/523 [09:49<25:02,  3.95s/it]Your max_length is set to 62, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 32%|███▏      | 167/523 [11:32<27:43,  4.67s/it]Your max_length is set to 62, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 35%|███▌      | 184/523 [12:39<23:39,  4.19s/it]Your max_length is set to 62, but you input_length is only 50. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 36%|███▌      | 186/523 [12:46<21:05,  3.75s/it]Your max_length is set to 62, but you input_length is only 37. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 37%|███▋      | 194/523 [13:20<22:17,  4.07s/it]Your max_length is set to 62, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 38%|███▊      | 200/523 [13:46<23:32,  4.37s/it]Your max_length is set to 62, but you input_length is only 56. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 40%|████      | 211/523 [14:32<23:45,  4.57s/it]Your max_length is set to 62, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 41%|████      | 213/523 [14:37<18:23,  3.56s/it]Your max_length is set to 62, but you input_length is only 41. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 42%|████▏     | 220/523 [15:07<20:13,  4.00s/it]Your max_length is set to 62, but you input_length is only 37. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 44%|████▍     | 229/523 [15:47<23:15,  4.75s/it]Your max_length is set to 62, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 50%|████▉     | 260/523 [18:28<27:46,  6.34s/it]Your max_length is set to 62, but you input_length is only 59. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 50%|████▉     | 261/523 [18:31<23:35,  5.40s/it]Your max_length is set to 62, but you input_length is only 47. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 52%|█████▏    | 273/523 [19:27<20:10,  4.84s/it]Your max_length is set to 62, but you input_length is only 44. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 55%|█████▌    | 289/523 [20:26<14:16,  3.66s/it]Your max_length is set to 62, but you input_length is only 59. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 60%|█████▉    | 313/523 [22:16<12:56,  3.70s/it]Your max_length is set to 62, but you input_length is only 26. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 62%|██████▏   | 322/523 [22:56<15:27,  4.62s/it]Your max_length is set to 62, but you input_length is only 35. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 64%|██████▍   | 334/523 [23:34<08:53,  2.82s/it]Your max_length is set to 62, but you input_length is only 16. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 72%|███████▏  | 375/523 [26:14<10:35,  4.29s/it]Your max_length is set to 62, but you input_length is only 59. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 74%|███████▍  | 386/523 [26:57<09:45,  4.27s/it]Your max_length is set to 62, but you input_length is only 32. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 75%|███████▍  | 392/523 [27:16<07:21,  3.37s/it]Your max_length is set to 62, but you input_length is only 48. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 75%|███████▌  | 393/523 [27:18<06:23,  2.95s/it]Your max_length is set to 62, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 78%|███████▊  | 408/523 [28:11<08:02,  4.20s/it]Your max_length is set to 62, but you input_length is only 19. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 79%|███████▉  | 414/523 [28:35<07:40,  4.23s/it]Your max_length is set to 62, but you input_length is only 42. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 79%|███████▉  | 415/523 [28:38<06:52,  3.82s/it]Your max_length is set to 62, but you input_length is only 49. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 80%|████████  | 420/523 [29:02<08:03,  4.69s/it]Your max_length is set to 62, but you input_length is only 52. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 85%|████████▍ | 444/523 [30:45<05:57,  4.52s/it]Your max_length is set to 62, but you input_length is only 43. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 89%|████████▊ | 464/523 [32:13<05:24,  5.50s/it]Your max_length is set to 62, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 90%|█████████ | 471/523 [32:39<03:11,  3.69s/it]Your max_length is set to 62, but you input_length is only 57. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 95%|█████████▍| 496/523 [34:31<01:47,  3.98s/it]Your max_length is set to 62, but you input_length is only 47. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      " 97%|█████████▋| 505/523 [35:03<01:16,  4.25s/it]Your max_length is set to 62, but you input_length is only 46. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "100%|██████████| 523/523 [36:11<00:00,  4.15s/it]\n"
     ]
    }
   ],
   "source": [
    "conclugen_df = data.progress_apply(generate_conclusion, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "premises = conclugen_df['premises'].tolist()\n",
    "references = conclugen_df['conclusion'].tolist()\n",
    "baseline_conclugen_predictions = conclugen_df['baseline_conclugen'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/baseline_conclugen_predictions.txt','w', encoding='utf-8') as outf:\n",
    "    for line in baseline_conclugen_predictions:\n",
    "        outf.write(line)\n",
    "        outf.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclugen_df.to_csv(\"../data/conclugen_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_df = pd.read_csv(\"../data/conc_comprehension_experiment.csv\",keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             523\n",
       "argument               523\n",
       "gt                     523\n",
       "masked_conc_attacks    523\n",
       "known_conc_attacks     523\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = se_df['argument'].tolist()\n",
    "references = se_df['gt'].tolist()\n",
    "masked_conc_attacks = se_df['masked_conc_attacks'].tolist()\n",
    "known_conc_attacks = se_df['known_conc_attacks'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/known_conc.txt\",'w', encoding='utf-8') as outf:\n",
    "    for line in known_conc_attacks:\n",
    "        outf.write(line)\n",
    "        outf.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16043b4afea6df4cc9c8277bea4f74cd7012ce4985455d3fd8e496ab2325b686"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('visummeval-backend': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
