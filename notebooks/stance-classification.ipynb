{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14279b0e-7dbe-40ba-827f-38a62638e1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9 (default, Jan 26 2021, 15:33:00) \n",
      "[GCC 8.4.0] on linux\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      ">>> \n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "KeyboardInterrupt\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "!python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffeb587-32e6-490b-b78b-b6a372a0dee7",
   "metadata": {},
   "source": [
    "## Load kialo data from scratch \n",
    "#### (scroll down if want to use already processed kialo data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec3f8fc-3d35-44e6-b5d4-e4c5a2ffdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad63585c-f0c6-4585-8865-f66e15745e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c15b74-fc24-4e1d-a832-1b8da75e1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "kialo_ds_path = '/mnt/ceph/storage/data-in-progress/data-research/arguana/arg-generation/multi-taks-counter-argument-generation/kialo_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ba0b50-33d4-445e-a54d-6b9276cbe1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kialo_df = pd.read_pickle(kialo_ds_path + '/kialo_train_df.pkl')\n",
    "valid_kialo_df = pd.read_pickle(kialo_ds_path + '/kialo_valid_df.pkl')\n",
    "test_kialo_df = pd.read_pickle(kialo_ds_path + '/kialo_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6907112-2ae8-4182-9a2d-6a0fa1538637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df):\n",
    "    \n",
    "    df = df.groupby('conclusion_text').agg({\n",
    "        'premises': lambda x: list(x)[0],\n",
    "        'counter' : lambda x: list(x)\n",
    "    }).reset_index()\n",
    "    \n",
    "    output_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        for premise in row['premises']:\n",
    "            num_tokens = len(premise.split())\n",
    "            if  num_tokens <= 200 and num_tokens > 3:\n",
    "                output_data.append((row['conclusion_text'], premise, 0))\n",
    "\n",
    "        for counter in row['counter']:\n",
    "            num_tokens = len(counter.split())\n",
    "            if  num_tokens <= 200 and num_tokens > 3:\n",
    "                output_data.append((row['conclusion_text'], counter, 1))\n",
    "\n",
    "    output_df = pd.DataFrame(output_data, columns=['claim1', 'claim2', 'label'])\n",
    "    \n",
    "    #Balancing the dataframe\n",
    "    g = output_df.groupby('label')\n",
    "    output_df = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26723968-6e40-4aab-ae3e-43727ec8b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_df(train_kialo_df)\n",
    "valid_df = create_df(valid_kialo_df)\n",
    "test_df  = create_df(test_kialo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2204b835-1aae-45f7-b31e-c65f402dd087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    47832\n",
       "0    47832\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8874d9cb-4bdd-4325-9f93-4cbd782ed9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3858\n",
       "0    3858\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253c6fc3-91a7-4ae4-a1c8-f1e8ab7e755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11227\n",
       "0    11227\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab68d92-bb48-423f-87a7-4258b9037988",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/kialo_stance_classification_training_data.csv', index=False)\n",
    "test_df.to_csv('../data/kialo_stance_classification_test_data.csv', index=False)\n",
    "valid_df.to_csv('../data/kialo_stance_classification_valid_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a848170-5458-42e3-9352-ede0560ba088",
   "metadata": {},
   "source": [
    "## Load already processed kialo data for tokenization and training for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8076231e-e037-46a6-a9c0-446ff5b239b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, RobertaTokenizer, RobertaForSequenceClassification, TextClassificationPipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19aad4a3-541c-4e55-beb8-391612b12bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('../data/kialo_stance_classification_training_data.csv')\n",
    "test_df  = pd.read_csv('../data/kialo_stance_classification_test_data.csv')\n",
    "valid_df = pd.read_csv('../data/kialo_stance_classification_valid_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e453c-7357-4483-a635-8f9b950196b0",
   "metadata": {},
   "source": [
    "### convert df into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbf9473-df1e-4ba4-a06b-44aae5926a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['input_txt'] = train_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n",
    "valid_df['input_txt'] = valid_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0181c74-2ff5-4365-8de1-c5bb03a135b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim1</th>\n",
       "      <th>claim2</th>\n",
       "      <th>label</th>\n",
       "      <th>input_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60236</th>\n",
       "      <td>From an Atheist perspective, there is no god a...</td>\n",
       "      <td>This is only true is atheism is presumed to be...</td>\n",
       "      <td>1</td>\n",
       "      <td>From an Atheist perspective, there is no god a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54604</th>\n",
       "      <td>The existence of suffering \\(natural evil is i...</td>\n",
       "      <td>The best possible world may still logically re...</td>\n",
       "      <td>1</td>\n",
       "      <td>The existence of suffering \\(natural evil is i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53594</th>\n",
       "      <td>Private schools preserve traditions that are a...</td>\n",
       "      <td>Children should not be forced to adopt traditi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Private schools preserve traditions that are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>Men will never accept a robot as a substitute ...</td>\n",
       "      <td>Sex robots require a level of paraphilia \\(Par...</td>\n",
       "      <td>0</td>\n",
       "      <td>Men will never accept a robot as a substitute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20963</th>\n",
       "      <td>Judaism</td>\n",
       "      <td>Jews have survived multiple attacks throughout...</td>\n",
       "      <td>0</td>\n",
       "      <td>Judaism &lt;/s&gt; Jews have survived multiple attac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  claim1  \\\n",
       "60236  From an Atheist perspective, there is no god a...   \n",
       "54604  The existence of suffering \\(natural evil is i...   \n",
       "53594  Private schools preserve traditions that are a...   \n",
       "4505   Men will never accept a robot as a substitute ...   \n",
       "20963                                            Judaism   \n",
       "\n",
       "                                                  claim2  label  \\\n",
       "60236  This is only true is atheism is presumed to be...      1   \n",
       "54604  The best possible world may still logically re...      1   \n",
       "53594  Children should not be forced to adopt traditi...      1   \n",
       "4505   Sex robots require a level of paraphilia \\(Par...      0   \n",
       "20963  Jews have survived multiple attacks throughout...      0   \n",
       "\n",
       "                                               input_txt  \n",
       "60236  From an Atheist perspective, there is no god a...  \n",
       "54604  The existence of suffering \\(natural evil is i...  \n",
       "53594  Private schools preserve traditions that are a...  \n",
       "4505   Men will never accept a robot as a substitute ...  \n",
       "20963  Judaism </s> Jews have survived multiple attac...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10).head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b66bb76-0ea3-42da-9a22-a82fbb596f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df.sample(frac=1))\n",
    "valid_dataset = Dataset.from_pandas(valid_df.sample(frac=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0dc41-0f7e-4618-b62d-b1893f6fa21d",
   "metadata": {},
   "source": [
    "## Apply Roberta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb54124f-629c-4517-9a9d-6f21da2f153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    #precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = metric.compute(predictions=preds, references=labels)\n",
    "    return {\n",
    "        'accuracy': acc['accuracy'],\n",
    "#         'f1': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f41b4e-dcf1-4421-b297-57d3eb8df9ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "# model = RobertaForSequenceClassification.from_pretrained('roberta-large').cuda()\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-base',num_labels=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ef3b39-8bfe-405d-b452-3d6e3de3111f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5661b371fba74b5095d5259c68001ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43bf499f5b84d708d32d95f0acda634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),batched=True)\n",
    "tokenized_valid = valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156f5c27-a4f1-4a83-a5f3-52227121174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments('../data/output/stance_classification', \n",
    "#                                   evaluation_strategy=\"epoch\", \n",
    "#                                   eval_steps=1000,\n",
    "#                                   save_steps=4000,\n",
    "#                                   learning_rate=2e-5,\n",
    "#                                   weight_decay=0.01,\n",
    "#                                   save_total_limit=5,\n",
    "#                                   num_train_epochs=10 , \n",
    "#                                   per_device_train_batch_size=8)\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    # output_dir: directory where the model checkpoints will be saved.\n",
    "    output_dir='../data/output/stance_classification',\n",
    "    # evaluation_strategy (default \"no\"):\n",
    "    # Possible values are:\n",
    "    # \"no\": No evaluation is done during training.\n",
    "    # \"steps\": Evaluation is done (and logged) every eval_steps.\n",
    "    # \"epoch\": Evaluation is done at the end of each epoch.\n",
    "    evaluation_strategy=\"steps\",\n",
    "    # eval_steps: Number of update steps between two evaluations if\n",
    "    # evaluation_strategy=\"steps\". Will default to the same value as\n",
    "    # logging_steps if not set.\n",
    "    eval_steps=200,\n",
    "    # logging_strategy (default: \"steps\"): The logging strategy to adopt during\n",
    "    # training (used to log training loss for example). Possible values are:\n",
    "    # \"no\": No logging is done during training.\n",
    "    # \"epoch\": Logging is done at the end of each epoch.\n",
    "    # \"steps\": Logging is done every logging_steps.\n",
    "    logging_strategy=\"steps\",\n",
    "    # logging_steps (default 500): Number of update steps between two logs if\n",
    "    # logging_strategy=\"steps\".\n",
    "    logging_steps=200,\n",
    "    # save_strategy (default \"steps\"):\n",
    "    # The checkpoint save strategy to adopt during training. Possible values are:\n",
    "    # \"no\": No save is done during training.\n",
    "    # \"epoch\": Save is done at the end of each epoch.\n",
    "    # \"steps\": Save is done every save_steps (default 500).\n",
    "    save_strategy=\"steps\",\n",
    "    # save_steps (default: 500): Number of updates steps before two checkpoint\n",
    "    # saves if save_strategy=\"steps\".\n",
    "    save_steps=600,\n",
    "    # learning_rate (default 5e-5): The initial learning rate for AdamW optimizer.\n",
    "    # Adam algorithm with weight decay fix as introduced in the paper\n",
    "    # Decoupled Weight Decay Regularization.\n",
    "    learning_rate=2e-5,\n",
    "    # per_device_train_batch_size: The batch size per GPU/TPU core/CPU for training.\n",
    "    per_device_train_batch_size=64,\n",
    "    # per_device_eval_batch_size: The batch size per GPU/TPU core/CPU for evaluation.\n",
    "    per_device_eval_batch_size=64,\n",
    "    # num_train_epochs (default 3.0): Total number of training epochs to perform\n",
    "    # (if not an integer, will perform the decimal part percents of the last epoch\n",
    "    # before stopping training).\n",
    "    num_train_epochs=1,\n",
    "    # load_best_model_at_end (default False): Whether or not to load the best model\n",
    "    # found during training at the end of training.\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model:\n",
    "    # Use in conjunction with load_best_model_at_end to specify the metric to use\n",
    "    # to compare two different models. Must be the name of a metric returned by\n",
    "    # the evaluation with or without the prefix \"eval_\".\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    # report_to:\n",
    "    # The list of integrations to report the results and logs to. Supported\n",
    "    # platforms are \"azure_ml\", \"comet_ml\", \"mlflow\", \"tensorboard\" and \"wandb\".\n",
    "    # Use \"all\" to report to all integrations installed, \"none\" for no integrations.\n",
    "#     report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_train, eval_dataset=tokenized_valid, compute_metrics=compute_metrics)\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    # Function that returns the model to train. It's useful to use a function\n",
    "    # instead of directly the model to make sure that we are always training\n",
    "    # an untrained model from scratch.\n",
    "    model=model,\n",
    "    # The training arguments.\n",
    "    args=args,\n",
    "    # The training dataset.\n",
    "    train_dataset=tokenized_train,\n",
    "    # The evaluation dataset. We use a small subset of the validation set\n",
    "    # composed of 150 samples to speed up computations...\n",
    "    eval_dataset=tokenized_valid.shuffle(42),#.select(range(150)),\n",
    "    # Even though the training set and evaluation set are already tokenized, the\n",
    "    # tokenizer is needed to pad the \"input_ids\" and \"attention_mask\" tensors\n",
    "    # to the length managed by the model. It does so one batch at a time, to\n",
    "    # use less memory as possible.\n",
    "    tokenizer=tokenizer,\n",
    "    # Function that will be called at the end of each evaluation phase on the whole\n",
    "    # arrays of predictions/labels to produce metrics.\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45fa30f-ddd5-4b5a-8ec6-56a9c44493bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running training *****\n",
      "  Num examples = 95664\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1495' max='1495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1495/1495 07:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.579500</td>\n",
       "      <td>0.501981</td>\n",
       "      <td>0.759850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.488100</td>\n",
       "      <td>0.523860</td>\n",
       "      <td>0.759850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.484840</td>\n",
       "      <td>0.773458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>0.462039</td>\n",
       "      <td>0.780327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.446397</td>\n",
       "      <td>0.791083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>0.442719</td>\n",
       "      <td>0.796786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>0.434321</td>\n",
       "      <td>0.796656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-200\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-200/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/output/stance_classification/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/stance_classification/checkpoint-200/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-400\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-400/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/output/stance_classification/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/stance_classification/checkpoint-400/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-600\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-600/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/output/stance_classification/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/stance_classification/checkpoint-600/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-800\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-800/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/output/stance_classification/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/stance_classification/checkpoint-800/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-1000\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-1000/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/output/stance_classification/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/stance_classification/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-1200\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-1200/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/output/stance_classification/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/stance_classification/checkpoint-1200/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-1400\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-1400/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/output/stance_classification/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/stance_classification/checkpoint-1400/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/output/stance_classification/checkpoint-1200 (score: 0.7967858994297563).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1495, training_loss=0.4676041695585219, metrics={'train_runtime': 425.0499, 'train_samples_per_second': 225.065, 'train_steps_per_second': 3.517, 'total_flos': 1.258512799997952e+16, 'train_loss': 0.4676041695585219, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c44b39a-800f-4124-8f76-9e880ab56378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saved/model\n",
      "Configuration saved in ./saved/model/config.json\n",
      "Model weights saved in ./saved/model/pytorch_model.bin\n",
      "tokenizer config file saved in ./saved/model/tokenizer_config.json\n",
      "Special tokens file saved in ./saved/model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./saved/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22005fe0-408f-47a6-b16d-2dc40efdc693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./saved/model/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ./saved/model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved/model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('./saved/model').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898ee77f-0cf8-4d34-b6b9-60636c9de7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab780184dc5048f5840b8d979262ee3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 22454\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='351' max='351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [351/351 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.25865212, -0.24357605],\n",
       "       [-1.9126097 ,  1.9990443 ],\n",
       "       [ 0.03257468,  0.10451257],\n",
       "       ...,\n",
       "       [ 0.34530902, -0.31135717],\n",
       "       [ 2.0949996 , -2.0372036 ],\n",
       "       [-1.9549632 ,  2.1160939 ]], dtype=float32), label_ids=array([0, 1, 1, ..., 0, 0, 1]), metrics={'test_loss': 0.42118096351623535, 'test_accuracy': 0.8068050236038122, 'test_runtime': 27.4998, 'test_samples_per_second': 816.516, 'test_steps_per_second': 12.764})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['input_txt'] = test_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n",
    "test_dataset = Dataset.from_pandas(test_df.sample(frac=1))\n",
    "tokenized_test = test_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),batched=True)\n",
    "\n",
    "pred=trainer.predict(tokenized_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4520d4-e26c-4d7d-b40f-2b46265007f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.argmax(pred.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ec606a-4173-474d-a3bc-facd408f6fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8068050236038122}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=scores, references=tokenized_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75238fd-f496-4fd9-a242-eea0fb2ce72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
