{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffeb587-32e6-490b-b78b-b6a372a0dee7",
   "metadata": {},
   "source": [
    "## Load kialo data from scratch \n",
    "#### (scroll down if want to use already processed kialo data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec3f8fc-3d35-44e6-b5d4-e4c5a2ffdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad63585c-f0c6-4585-8865-f66e15745e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c15b74-fc24-4e1d-a832-1b8da75e1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "kialo_ds_path = '../../../data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation/kialo_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ba0b50-33d4-445e-a54d-6b9276cbe1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kialo_df = pd.read_pickle(kialo_ds_path + '/kialo_train_df.pkl')\n",
    "valid_kialo_df = pd.read_pickle(kialo_ds_path + '/kialo_valid_df.pkl')\n",
    "test_kialo_df = pd.read_pickle(kialo_ds_path + '/kialo_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6907112-2ae8-4182-9a2d-6a0fa1538637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df):\n",
    "    \n",
    "    df = df.groupby('conclusion_text').agg({\n",
    "        'premises': lambda x: list(x)[0],\n",
    "        'counter' : lambda x: list(x)\n",
    "    }).reset_index()\n",
    "    \n",
    "    output_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        for premise in row['premises']:\n",
    "            num_tokens = len(premise.split())\n",
    "            if  num_tokens <= 200 and num_tokens > 3:\n",
    "                output_data.append((row['conclusion_text'], premise, 0))\n",
    "\n",
    "        for counter in row['counter']:\n",
    "            num_tokens = len(counter.split())\n",
    "            if  num_tokens <= 200 and num_tokens > 3:\n",
    "                output_data.append((row['conclusion_text'], counter, 1))\n",
    "\n",
    "    output_df = pd.DataFrame(output_data, columns=['claim1', 'claim2', 'label'])\n",
    "    \n",
    "    #Balancing the dataframe\n",
    "    g = output_df.groupby('label')\n",
    "    output_df = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26723968-6e40-4aab-ae3e-43727ec8b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_df(train_kialo_df)\n",
    "valid_df = create_df(valid_kialo_df)\n",
    "test_df  = create_df(test_kialo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2204b835-1aae-45f7-b31e-c65f402dd087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    47832\n",
       "0    47832\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8874d9cb-4bdd-4325-9f93-4cbd782ed9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3858\n",
       "0    3858\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "253c6fc3-91a7-4ae4-a1c8-f1e8ab7e755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11227\n",
       "0    11227\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab68d92-bb48-423f-87a7-4258b9037988",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/kialo_stance_classification_training_data.csv', index=False)\n",
    "test_df.to_csv('../data/kialo_stance_classification_test_data.csv', index=False)\n",
    "valid_df.to_csv('../data/kialo_stance_classification_valid_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a848170-5458-42e3-9352-ede0560ba088",
   "metadata": {},
   "source": [
    "## Load already processed kialo data for tokenization and training for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8076231e-e037-46a6-a9c0-446ff5b239b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, RobertaTokenizer, RobertaForSequenceClassification, TextClassificationPipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19aad4a3-541c-4e55-beb8-391612b12bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/kialo_stance_classification_training_data.csv')\n",
    "test_df  = pd.read_csv('../data/kialo_stance_classification_test_data.csv')\n",
    "valid_df = pd.read_csv('../data/kialo_stance_classification_valid_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e453c-7357-4483-a635-8f9b950196b0",
   "metadata": {},
   "source": [
    "### convert df into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fbf9473-df1e-4ba4-a06b-44aae5926a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['input_txt'] = train_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n",
    "valid_df['input_txt'] = valid_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0181c74-2ff5-4365-8de1-c5bb03a135b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim1</th>\n",
       "      <th>claim2</th>\n",
       "      <th>label</th>\n",
       "      <th>input_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93467</th>\n",
       "      <td>Governments shouldn't subsidize ethanol.</td>\n",
       "      <td>It is the nature of governments to \"subsidize\" or \"mandate\" preferences. They do it by establishing and enforcing laws They should promote those areas that are in the public best interest. Replacing fossil fuels which have historically benefited countries financially have come with devastating environmental and sociatal consequences. Government should therefore support and promote technologies that better address sociatal needs and minimize negative consequences.</td>\n",
       "      <td>1</td>\n",
       "      <td>Governments shouldn't subsidize ethanol. &lt;/s&gt; It is the nature of governments to \"subsidize\" or \"mandate\" preferences. They do it by establishing and enforcing laws They should promote those areas that are in the public best interest. Replacing fossil fuels which have historically benefited countries financially have come with devastating environmental and sociatal consequences. Government should therefore support and promote technologies that better address sociatal needs and minimize negative consequences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57615</th>\n",
       "      <td>For economic reasons.</td>\n",
       "      <td>Fossil Fuel cars have been a primary driver of economies world wide for nearly 100 years, driving innovation, employment, making transport cheaper and more efficient. It will take at least 20 years for EVs to gain significant market share to make such a claim.</td>\n",
       "      <td>1</td>\n",
       "      <td>For economic reasons. &lt;/s&gt; Fossil Fuel cars have been a primary driver of economies world wide for nearly 100 years, driving innovation, employment, making transport cheaper and more efficient. It will take at least 20 years for EVs to gain significant market share to make such a claim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58404</th>\n",
       "      <td>Portraying gender equality in video games may make future games less violent which is beneficial.</td>\n",
       "      <td>There is no beneficial effect of making future games less violent. Games are already split up into adult games and children-friendly games. Showing violence is also a way to show the consequences of it. Games such as Heavy Rain are a massive success.</td>\n",
       "      <td>1</td>\n",
       "      <td>Portraying gender equality in video games may make future games less violent which is beneficial. &lt;/s&gt; There is no beneficial effect of making future games less violent. Games are already split up into adult games and children-friendly games. Showing violence is also a way to show the consequences of it. Games such as Heavy Rain are a massive success.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69168</th>\n",
       "      <td>The right to bodily autonomy gives individuals a right to consent to harm, or even death.</td>\n",
       "      <td>We regulate what people are allowed to do all of the time in the name of public safety or personal interest \\(e.g. drinking age, medicine regulation\\).</td>\n",
       "      <td>1</td>\n",
       "      <td>The right to bodily autonomy gives individuals a right to consent to harm, or even death. &lt;/s&gt; We regulate what people are allowed to do all of the time in the name of public safety or personal interest \\(e.g. drinking age, medicine regulation\\).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32116</th>\n",
       "      <td>The legalization of drugs means that they are taken, and disposed of, more safely and cautiously than in the current environment.</td>\n",
       "      <td>Dangerous substitute drugs will be contained.</td>\n",
       "      <td>0</td>\n",
       "      <td>The legalization of drugs means that they are taken, and disposed of, more safely and cautiously than in the current environment. &lt;/s&gt; Dangerous substitute drugs will be contained.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                  claim1  \\\n",
       "93467                                                                                           Governments shouldn't subsidize ethanol.   \n",
       "57615                                                                                                              For economic reasons.   \n",
       "58404                                  Portraying gender equality in video games may make future games less violent which is beneficial.   \n",
       "69168                                          The right to bodily autonomy gives individuals a right to consent to harm, or even death.   \n",
       "32116  The legalization of drugs means that they are taken, and disposed of, more safely and cautiously than in the current environment.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    claim2  \\\n",
       "93467  It is the nature of governments to \"subsidize\" or \"mandate\" preferences. They do it by establishing and enforcing laws They should promote those areas that are in the public best interest. Replacing fossil fuels which have historically benefited countries financially have come with devastating environmental and sociatal consequences. Government should therefore support and promote technologies that better address sociatal needs and minimize negative consequences.   \n",
       "57615                                                                                                                                                                                                                 Fossil Fuel cars have been a primary driver of economies world wide for nearly 100 years, driving innovation, employment, making transport cheaper and more efficient. It will take at least 20 years for EVs to gain significant market share to make such a claim.   \n",
       "58404                                                                                                                                                                                                                           There is no beneficial effect of making future games less violent. Games are already split up into adult games and children-friendly games. Showing violence is also a way to show the consequences of it. Games such as Heavy Rain are a massive success.   \n",
       "69168                                                                                                                                                                                                                                                                                                                              We regulate what people are allowed to do all of the time in the name of public safety or personal interest \\(e.g. drinking age, medicine regulation\\).   \n",
       "32116                                                                                                                                                                                                                                                                                                                                                                                                                                        Dangerous substitute drugs will be contained.   \n",
       "\n",
       "       label  \\\n",
       "93467      1   \n",
       "57615      1   \n",
       "58404      1   \n",
       "69168      1   \n",
       "32116      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               input_txt  \n",
       "93467  Governments shouldn't subsidize ethanol. </s> It is the nature of governments to \"subsidize\" or \"mandate\" preferences. They do it by establishing and enforcing laws They should promote those areas that are in the public best interest. Replacing fossil fuels which have historically benefited countries financially have come with devastating environmental and sociatal consequences. Government should therefore support and promote technologies that better address sociatal needs and minimize negative consequences.  \n",
       "57615                                                                                                                                                                                                                                    For economic reasons. </s> Fossil Fuel cars have been a primary driver of economies world wide for nearly 100 years, driving innovation, employment, making transport cheaper and more efficient. It will take at least 20 years for EVs to gain significant market share to make such a claim.  \n",
       "58404                                                                                                                                                                  Portraying gender equality in video games may make future games less violent which is beneficial. </s> There is no beneficial effect of making future games less violent. Games are already split up into adult games and children-friendly games. Showing violence is also a way to show the consequences of it. Games such as Heavy Rain are a massive success.  \n",
       "69168                                                                                                                                                                                                                                                                             The right to bodily autonomy gives individuals a right to consent to harm, or even death. </s> We regulate what people are allowed to do all of the time in the name of public safety or personal interest \\(e.g. drinking age, medicine regulation\\).  \n",
       "32116                                                                                                                                                                                                                                                                                                                                               The legalization of drugs means that they are taken, and disposed of, more safely and cautiously than in the current environment. </s> Dangerous substitute drugs will be contained.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10).head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b66bb76-0ea3-42da-9a22-a82fbb596f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df.sample(frac=1))\n",
    "valid_dataset = Dataset.from_pandas(valid_df.sample(frac=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0dc41-0f7e-4618-b62d-b1893f6fa21d",
   "metadata": {},
   "source": [
    "## Apply Roberta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb54124f-629c-4517-9a9d-6f21da2f153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    #precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = metric.compute(predictions=preds, references=labels)\n",
    "    return {\n",
    "        'accuracy': acc['accuracy'],\n",
    "#         'f1': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6f41b4e-dcf1-4421-b297-57d3eb8df9ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "# model = RobertaForSequenceClassification.from_pretrained('roberta-large').cuda()\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-base',num_labels=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88ef3b39-8bfe-405d-b452-3d6e3de3111f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e094f17df8fe4cccaca2a0cd265c5591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254d4509f04147f89daa018399e295d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),batched=True)\n",
    "tokenized_valid = valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "156f5c27-a4f1-4a83-a5f3-52227121174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments('../data/output/stance_classification', \n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  eval_steps=1000,\n",
    "                                  save_steps=4000,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  weight_decay=0.01,\n",
    "                                  save_total_limit=5,\n",
    "                                  num_train_epochs=10 , \n",
    "                                  per_device_train_batch_size=8)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_train, eval_dataset=tokenized_valid, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45fa30f-ddd5-4b5a-8ec6-56a9c44493bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running training *****\n",
      "  Num examples = 95664\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59790\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18795' max='59790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18795/59790 27:28 < 59:56, 11.40 it/s, Epoch 3.14/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.694453</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.693455</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.693465</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-4000\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-4000/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-4000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-8000\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-8000/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [../data/output/stance_classification/checkpoint-4000] due to args.save_total_limit\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-12000\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-12000/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-12000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/stance_classification/checkpoint-16000\n",
      "Configuration saved in ../data/output/stance_classification/checkpoint-16000/config.json\n",
      "Model weights saved in ../data/output/stance_classification/checkpoint-16000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: input_txt, claim2, __index_level_0__, claim1.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7716\n",
      "  Batch size = 16\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m                 if (\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44b39a-800f-4124-8f76-9e880ab56378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
