{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../multitask-learning-transformers/shared_encoder')\n",
    "sys.path.append('../src-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm as tqdm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload \n",
    "import transformers\n",
    "#from accelerate import Accelerator\n",
    "from filelock import FileLock\n",
    "from transformers import set_seed\n",
    "from transformers.file_utils import is_offline_mode\n",
    "from multitask_model import MultitaskModel\n",
    "#from preprocess import convert_to_features\n",
    "from multitask_data_collator import MultitaskTrainer, NLPDataCollator\n",
    "from multitask_eval import multitask_eval_fn\n",
    "from checkpoint_model import save_model\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from evaluate_bleu import *\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('../../../data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation/reddit_data/conclusion_and_ca_generation/preprocessed_train_conclusion_all.pkl')\n",
    "df_validation = pd.read_pickle('../../../data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation/reddit_data/conclusion_and_ca_generation/sample_valid_conclusion_all_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute once to create a sample from the stance data\n",
    "# stance_train_df = pd.read_csv('../data/kialo_stance_classification_training_data.csv')\n",
    "# stance_valid_df = pd.read_csv('../data/kialo_stance_classification_valid_data.csv')\n",
    "\n",
    "# stance_train_df['input_txt'] = stance_train_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n",
    "# stance_valid_df['input_txt'] = stance_valid_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n",
    "# stance_train_df = stance_train_df.rename(columns={'label':'labels'})\n",
    "# stance_valid_df = stance_valid_df.rename(columns={'label':'labels'})\n",
    "\n",
    "# stance_train_df.sample(50000).to_pickle('../data/kialo_stance_classification_training_data_sample.csv')\n",
    "# stance_valid_df.sample(2000).to_pickle('../data/kialo_stance_classification_valid_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_train_df = pd.read_pickle('../data/kialo_stance_classification_training_data_sample.csv')\n",
    "stance_valid_df = pd.read_pickle('../data/kialo_stance_classification_valid_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['counter_gen', 'conclusion_gen', 'stance_cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'facebook/bart-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [model_name] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultitaskBartModel(transformers.PreTrainedModel):\n",
    "    def __init__(self, encoder, taskmodels_dict):\n",
    "        \"\"\"\n",
    "        Setting MultitaskModel up as a PretrainedModel allows us\n",
    "        to take better advantage of Trainer features\n",
    "        \"\"\"\n",
    "        super().__init__(transformers.PretrainedConfig())\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, model_name, model_type_dict, model_config_dict):\n",
    "        \"\"\"\n",
    "        This creates a MultitaskModel using the model class and config objects\n",
    "        from single-task models.\n",
    "\n",
    "        We do this by creating each single-task model, and having them share\n",
    "        the same encoder transformer.\n",
    "        \"\"\"\n",
    "        shared_encoder = None\n",
    "        taskmodels_dict = {}\n",
    "        for task_name, model_type in model_type_dict.items():\n",
    "            model = model_type.from_pretrained(\n",
    "                model_name,\n",
    "                config=model_config_dict[task_name],\n",
    "            )\n",
    "            if shared_encoder is None:\n",
    "                shared_encoder = model.model.encoder\n",
    "            else:\n",
    "                model.model.encoder = shared_encoder\n",
    "            taskmodels_dict[task_name] = model\n",
    "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, model_folder, model_type_dict, model_config_dict):\n",
    "        \"\"\"\n",
    "        This loads a MultitaskModel using the model class and config objects\n",
    "        from single-task models.\n",
    "        \"\"\"\n",
    "        shared_encoder = None\n",
    "        taskmodels_dict = {}\n",
    "        for task_name, model_type in model_type_dict.items():\n",
    "            model = model_type.from_pretrained(\n",
    "                f\"{model_folder}/{task_name}_model\",\n",
    "                config=model_config_dict[task_name],\n",
    "            )\n",
    "            if shared_encoder is None:\n",
    "                shared_encoder = model.model.encoder\n",
    "            else:\n",
    "                model.model.encoder = shared_encoder\n",
    "            taskmodels_dict[task_name] = model\n",
    "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
    "\n",
    "    def forward(self, task_name, **kwargs):\n",
    "        return self.taskmodels_dict[task_name](**kwargs)\n",
    "    \n",
    "    def generate(self, input_ids, attention_mask, task_name, gen_kwargs):\n",
    "       \n",
    "        return self.taskmodels_dict[task_name].generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **gen_kwargs,\n",
    "        )\n",
    "\n",
    "    def resize_token_embeddings(self, new_num_tokens):\n",
    "        for task_name, model in self.taskmodels_dict.items():\n",
    "            model.resize_token_embeddings(new_num_tokens)\n",
    "            \n",
    "            \n",
    "    def predict_stances(self, dataset, task_name='stance_cls'):\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=16)\n",
    "        all_labels = []\n",
    "        for idx, batch in enumerate(data_loader):\n",
    "            input_ids, attention_mask = batch['input_ids'].cuda(), batch['attention_mask'].cuda()\n",
    "            output = self.taskmodels_dict[task_name](input_ids, attention_mask)\n",
    "            pred_labels = output.logits.argmax(-1).cpu().tolist()\n",
    "            all_labels+= pred_labels\n",
    "        \n",
    "        return all_labels\n",
    "        \n",
    "def preprocess_function(examples, tokenizer, input_clm, output_clm, max_input_length=512, max_target_length=512):\n",
    "    input_examples  = examples[input_clm]\n",
    "    output_examples = examples[output_clm]\n",
    "        \n",
    "    if isinstance(input_examples[0], list):\n",
    "        input_examples = [' '.join(x) for x in input_examples]\n",
    "    \n",
    "    processed_output = tokenizer(input_examples, max_length=max_input_length, truncation=True, padding='max_length')\n",
    "    \n",
    "    if isinstance(output_examples[0], list):\n",
    "        output_examples = [' '.join(x) for x in output_examples]\n",
    "    \n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(output_examples, max_length=max_target_length, truncation=True, padding='max_length')    \n",
    "    \n",
    "    processed_output[\"labels\"] = labels[\"input_ids\"]\n",
    "    return processed_output\n",
    "\n",
    "def save_model(multitask_model, fold='mt-v2', tasks = ['stance_cls']):\n",
    "    for task_name in tasks:\n",
    "        multitask_model.taskmodels_dict[task_name].config.to_json_file(\n",
    "            f\"../data/output/ca-final-models/{fold}/{task_name}_model/config.json\"\n",
    "        )\n",
    "        torch.save(\n",
    "            multitask_model.taskmodels_dict[task_name].state_dict(),\n",
    "            f\"../data/output/ca-final-models/{fold}/{task_name}_model/pytorch_model.bin\",\n",
    "        )\n",
    "        tokenizer.save_pretrained(f\"../data/output/ca-final-models/{fold}/{task_name}_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training single model for stance classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/bart-large/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/3f12fb71b844fcb7d591fdd4e55027da90d7b5dd6aa5430ad00ec6d76585f26c.bc22f15dc7ba074ee0a60bdd34c5f2fe3b6d746f89e765303376c51aff04e260\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-large/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/d065edfe6954baf0b989a2063b26eb07e8c4d0b19354b5c74af9a51f5518df6e.6ca4df1a6ec59aa763989ceec10dff41dde19f0f0824b9f5d3fcd35a8abffdb2\n",
      "All model checkpoint weights were used when initializing BartForSequenceClassification.\n",
      "\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.out_proj.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight', 'classification_head.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/facebook/bart-large/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/3f12fb71b844fcb7d591fdd4e55027da90d7b5dd6aa5430ad00ec6d76585f26c.bc22f15dc7ba074ee0a60bdd34c5f2fe3b6d746f89e765303376c51aff04e260\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/bart-large/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/0d6fc8b2ef1860c1f8f0baff4b021e3426cc7d11b153f98e563b799603ee2f25.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/facebook/bart-large/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/6e75e35f0bdd15870c98387e13b93a8e100237eb33ad99c36277a0562bd6d850.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/facebook/bart-large/resolve/main/tokenizer.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/d94f53c8851dcda40774f97280e634b94b721a58e71bcc152b5f51d0d49a046a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/facebook/bart-large/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/bart-large/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/facebook/bart-large/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/1abf196c889c24daca2909359ca2090e5fcbfa21a9ea36d763f70adbafb500d7.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
      "loading configuration file https://huggingface.co/facebook/bart-large/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/3f12fb71b844fcb7d591fdd4e55027da90d7b5dd6aa5430ad00ec6d76585f26c.bc22f15dc7ba074ee0a60bdd34c5f2fe3b6d746f89e765303376c51aff04e260\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stance_model = MultitaskBartModel.create(\n",
    "    model_name=model_name,\n",
    "    model_type_dict={\n",
    "        \"stance_cls\": transformers.BartForSequenceClassification,\n",
    "    },\n",
    "    model_config_dict={\n",
    "        \"stance_cls\": transformers.AutoConfig.from_pretrained('facebook/bart-large', num_labels=2)\n",
    "    },\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4dd1a44f194b30a9ab6f7ac76c3d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2ecf6d41174b958dafb213c14b941b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stance_train_dataset = Dataset.from_pandas(stance_train_df)\n",
    "stance_valid_dataset = Dataset.from_pandas(stance_valid_df)\n",
    "\n",
    "training_ds_dict = {'stance_cls': stance_train_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),\n",
    "                                           remove_columns=['claim1', 'claim2', 'input_txt', '__index_level_0__'],batched=True)}\n",
    "valid_ds_dict = {'stance_cls': stance_valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),\n",
    "                                           remove_columns=['claim1', 'claim2', 'input_txt', '__index_level_0__'],batched=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "trainer = MultitaskTrainer(\n",
    "    model=stance_model,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir='../data/output/ca-final-models/bart-based-stance-classifier',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=5e-5,\n",
    "        do_train=True,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=500,\n",
    "        eval_steps=500\n",
    "    ),\n",
    "    #data_collator=DataCollatorForSeq2Seq(tokenizer, multitask_model),\n",
    "    #callbacks = [MyTrainerCallback(multitask_model, valid_ds_dict)],\n",
    "    train_dataset=training_ds_dict,\n",
    "    eval_dataset =valid_ds_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 50000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9375' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9375/9375 39:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>0.632229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.568599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.621323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.555300</td>\n",
       "      <td>0.537356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>0.529795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.505297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.529449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.423900</td>\n",
       "      <td>0.473925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.466852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.446495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.467251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.446038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.331800</td>\n",
       "      <td>0.587821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.267400</td>\n",
       "      <td>0.501906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.267100</td>\n",
       "      <td>0.532224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.259900</td>\n",
       "      <td>0.572528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.537739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.505119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-1000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-1000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-1000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-1500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-1500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-1500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-2000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-2000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-2000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-2500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-2500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-2500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-3000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-3000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-3000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-3500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-3500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-3500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-4000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-4000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-4000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-4500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-4500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-4500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-5000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-5000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-5000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-5500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-5500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-5500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-6000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-6000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-6000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-6500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-6500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-6500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-7000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-7000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-7000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-7500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-7500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-7500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-8000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-8000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-8000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-8500\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-8500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-8500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-9000\n",
      "Configuration saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-9000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/bart-based-stance-classifier/checkpoint-9000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9375, training_loss=0.4128147021484375, metrics={'train_runtime': 2400.6514, 'train_samples_per_second': 62.483, 'train_steps_per_second': 3.905, 'total_flos': 8.15087227392e+16, 'train_loss': 0.4128147021484375, 'epoch': 3.0})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "save_model(stance_model, fold='bart-based-stance-classifier', tasks = ['stance_cls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/bart-large/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current//sile2804/.cache/huggingface/transformers/3f12fb71b844fcb7d591fdd4e55027da90d7b5dd6aa5430ad00ec6d76585f26c.bc22f15dc7ba074ee0a60bdd34c5f2fe3b6d746f89e765303376c51aff04e260\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForSequenceClassification.\n",
      "\n",
      "All the weights of BartForSequenceClassification were initialized from the model checkpoint at ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForSequenceClassification for predictions without further training.\n",
      "Didn't find file ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/added_tokens.json. We won't load it.\n",
      "loading file ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/vocab.json\n",
      "loading file ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/merges.txt\n",
      "loading file ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/tokenizer.json\n",
      "loading file None\n",
      "loading file ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/special_tokens_map.json\n",
      "loading file ../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "stance_model = MultitaskBartModel.load(\n",
    "    model_folder='../data/output/ca-final-models/bart-based-stance-classifier',\n",
    "    model_type_dict={\n",
    "        \"stance_cls\": transformers.BartForSequenceClassification,\n",
    "    },\n",
    "    model_config_dict={\n",
    "        \"stance_cls\": transformers.AutoConfig.from_pretrained('facebook/bart-large', num_labels=2)\n",
    "    }\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('../data/output/ca-final-models/bart-based-stance-classifier/stance_cls_model')\n",
    "\n",
    "_ = stance_model.to('cuda')\n",
    "_ = stance_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2288850c5e58429db5d5d2135e801be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stance_valid_dataset = Dataset.from_pandas(stance_valid_df)\n",
    "ds = stance_valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True), remove_columns=['claim1', 'claim2', 'input_txt', '__index_level_0__'],batched=True)\n",
    "ds.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.814}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = stance_model.predict_stances(ds)\n",
    "true_labels = ds['labels'].tolist()\n",
    "metric.compute(predictions=pred_labels, references=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f4e37e1cb64763b1720eb51d13352f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stance_test_df = pd.read_csv('../data/kialo_stance_classification_test_data.csv')\n",
    "stance_test_df['input_txt'] = stance_test_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n",
    "stance_test_df = stance_test_df.rename(columns={'label':'labels'})\n",
    "\n",
    "stance_valid_dataset = Dataset.from_pandas(stance_test_df)\n",
    "ds = stance_valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True), remove_columns=['claim1', 'claim2', 'input_txt'],batched=True)\n",
    "ds.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.814}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predpred_labels= stance_model.predict_stances(ds)\n",
    "true_labels = ds['labels'].tolist()\n",
    "metric.compute(predictions=pred_labels, references=true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Training the MultiTask Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.out_proj.bias', 'classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "multitask_model = MultitaskBartModel.create(\n",
    "    model_name=model_name,\n",
    "    model_type_dict={\n",
    "        \"counter_gen\": transformers.BartForConditionalGeneration,\n",
    "        \"conclusion_gen\": transformers.BartForConditionalGeneration,\n",
    "        \"stance_cls\": transformers.BartForSequenceClassification,\n",
    "    },\n",
    "    model_config_dict={\n",
    "        \"counter_gen\": transformers.AutoConfig.from_pretrained('facebook/bart-large'),\n",
    "        \"conclusion_gen\": transformers.AutoConfig.from_pretrained('facebook/bart-large'),\n",
    "        \"stance_cls\": transformers.AutoConfig.from_pretrained('facebook/bart-large', num_labels=2)\n",
    "    },\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(df_train)\n",
    "valid_ds = Dataset.from_pandas(df_validation)\n",
    "\n",
    "stance_train_dataset = Dataset.from_pandas(stance_train_df)\n",
    "stance_valid_dataset = Dataset.from_pandas(stance_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3190eb6c4d430e8d685730112e936a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28944e6cf3405dab61ca7567bd9f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e47abc74b89403aa3f0a9df0f3d4116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_ds_dict = {\n",
    "    'conclusion_gen':train_ds.map(lambda a: preprocess_function(a, tokenizer, 'post', 'title', 512, 100),\n",
    "                                  remove_columns=['post_id', 'split', 'comment_id', 'title', 'post', 'n_sentences', 'counter', 'bot_comment', 'counter_conclusion', 'counter_conclusions', '__index_level_0__'],\n",
    "                                  batched=True),\n",
    "    'counter_gen':train_ds.map(lambda a: preprocess_function(a, tokenizer, 'post', 'counter', 512, 256),\n",
    "                     remove_columns=['post_id', 'split', 'comment_id', 'title', 'post', 'n_sentences', 'counter', 'bot_comment', 'counter_conclusion', 'counter_conclusions', '__index_level_0__'],\n",
    "                     batched=True),\n",
    "    'stance_cls': stance_train_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),\n",
    "                                           remove_columns=['claim1', 'claim2', 'input_txt', '__index_level_0__'],batched=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f487e7332f455f9c2529bde3e183cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f166c949e1ee40c1800b1315dd5e52e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb21af5e5808429c81821c4e1a3f1285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_ds_dict = {\n",
    "    'conclusion_gen':valid_ds.map(lambda a: preprocess_function(a, tokenizer, 'post', 'title', 512, 100),\n",
    "                                  remove_columns=['post_id', 'split', 'comment_id', 'title', 'post', 'n_sentences', 'counter', 'bot_comment', '__index_level_0__'],\n",
    "                                  batched=True),\n",
    "    'counter_gen':valid_ds.map(lambda a: preprocess_function(a, tokenizer, 'post', 'counter', 512, 256),\n",
    "                     remove_columns=['post_id', 'split', 'comment_id', 'title', 'post', 'n_sentences', 'counter', 'bot_comment', '__index_level_0__'],\n",
    "                     batched=True),\n",
    "    'stance_cls': stance_valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True),\n",
    "                                           remove_columns=['claim1', 'claim2', 'input_txt', '__index_level_0__'],batched=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = MultitaskTrainer(\n",
    "    model=multitask_model,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir='../data/output/ca-final-models/mt-v3',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=5e-5,\n",
    "        do_train=True,\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        #evaluation_strategy='steps',\n",
    "        save_steps=500,\n",
    "        #eval_steps=500\n",
    "    ),\n",
    "    #data_collator=DataCollatorForSeq2Seq(tokenizer, multitask_model),\n",
    "    #callbacks = [MyTrainerCallback(multitask_model, valid_ds_dict)],\n",
    "    train_dataset=training_ds_dict,\n",
    "    #eval_dataset =valid_ds_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 101408\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6339\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6339' max='6339' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6339/6339 45:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.816500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.943500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.870900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.820200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.839500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.829300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.831400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.745400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.811800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-500\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-1000\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-1000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-1000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-1500\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-1500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-1500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-2000\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-2000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-2000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-2500\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-2500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-2500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-3000\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-3000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-3000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-3500\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-3500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-3500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-4000\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-4000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-4000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-4500\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-4500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-4500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-5000\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-5000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-5000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-5500\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-5500/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-5500/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ../data/output/ca-final-models/mt-v3/checkpoint-6000\n",
      "Configuration saved in ../data/output/ca-final-models/mt-v3/checkpoint-6000/config.json\n",
      "Model weights saved in ../data/output/ca-final-models/mt-v3/checkpoint-6000/pytorch_model.bin\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6339, training_loss=0.903246081464015, metrics={'train_runtime': 2712.6629, 'train_samples_per_second': 37.383, 'train_steps_per_second': 2.337, 'total_flos': 1.7766239821386547e+17, 'train_loss': 0.903246081464015, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../data/output/ca-final-models/mt-v3/counter_gen_model/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/ca-final-models/mt-v3/counter_gen_model/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/output/ca-final-models/mt-v3/conclusion_gen_model/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/ca-final-models/mt-v3/conclusion_gen_model/special_tokens_map.json\n",
      "tokenizer config file saved in ../data/output/ca-final-models/mt-v3/stance_cls_model/tokenizer_config.json\n",
      "Special tokens file saved in ../data/output/ca-final-models/mt-v3/stance_cls_model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "save_model(multitask_model, fold='mt-v3', tasks=['counter_gen', 'conclusion_gen', 'stance_cls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate stance performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "multitask_model = MultitaskBartModel.load(\n",
    "    model_folder='../data/output/ca-final-models/mt-v3',\n",
    "    model_type_dict={\n",
    "        \"counter_gen\": transformers.BartForConditionalGeneration,\n",
    "        \"conclusion_gen\": transformers.BartForConditionalGeneration,\n",
    "        \"stance_cls\": transformers.BartForSequenceClassification,\n",
    "    },\n",
    "    model_config_dict={\n",
    "        \"counter_gen\": transformers.AutoConfig.from_pretrained('facebook/bart-large'),\n",
    "        \"conclusion_gen\": transformers.AutoConfig.from_pretrained('facebook/bart-large'),\n",
    "        \"stance_cls\": transformers.AutoConfig.from_pretrained('facebook/bart-large', num_labels=2)\n",
    "    }\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('../data/output/ca-final-models/mt-v3/counter_gen_model')\n",
    "\n",
    "_ = multitask_model.to('cuda')\n",
    "_ = multitask_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate stance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd7e13a972b471dada2453881e514ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stance_valid_dataset = Dataset.from_pandas(stance_valid_df)\n",
    "ds = stance_valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True), remove_columns=['claim1', 'claim2', 'input_txt', '__index_level_0__'],batched=True)\n",
    "ds.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.826}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = multitask_model.predict_stances(ds)\n",
    "true_labels = ds['labels'].tolist()\n",
    "metric.compute(predictions=pred_labels, references=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6cedf7c76c4a87b254bc809fcfba36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stance_test_df = pd.read_csv('../data/kialo_stance_classification_test_data.csv')\n",
    "stance_test_df['input_txt'] = stance_test_df.apply(lambda x: x['claim1'] + ' </s> ' + x['claim2'], axis=1)\n",
    "stance_test_df = stance_test_df.rename(columns={'label':'labels'})\n",
    "\n",
    "stance_valid_dataset = Dataset.from_pandas(stance_test_df)\n",
    "ds = stance_valid_dataset.map(lambda a: tokenizer(a['input_txt'], padding='max_length', max_length=256, truncation=True), remove_columns=['claim1', 'claim2', 'input_txt'],batched=True)\n",
    "ds.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8351741337846263}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = multitask_model.predict_stances(ds)\n",
    "true_labels = ds['labels'].tolist()\n",
    "metric.compute(predictions=pred_labels, references=true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_texts(model, tokenizer, df, gen_kwargs, task_name='counter_gen'):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    ds = Dataset.from_pandas(df)\n",
    "    enc_ds = ds.map(lambda a: preprocess_function(a, tokenizer, 'post', 'counter', 512, 256),\n",
    "                          remove_columns=['post_id', 'split', 'comment_id', 'title', 'post', 'n_sentences', 'counter', 'bot_comment', '__index_level_0__'],\n",
    "                          batched=True)\n",
    "    enc_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    dataloader = torch.utils.data.DataLoader(enc_ds, batch_size=16)\n",
    "\n",
    "    generated_texts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            generated_tokens = model.generate(\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                task_name,\n",
    "                gen_kwargs\n",
    "            )\n",
    "            \n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "                \n",
    "            generated_tokens = generated_tokens.cpu().numpy()\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            \n",
    "            generated_texts += decoded_preds\n",
    "    \n",
    "    return generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('../../../data-ceph/arguana/arg-generation/multi-taks-counter-argument-generation/reddit_data/conclusion_and_ca_generation/test_conclusion_all_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63990b7e05d740f483fb1c2c11ef3a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_kwargs = {\n",
    "    \"do_sample\": False, \n",
    "    \"max_length\":100,\n",
    "    \"min_length\":50,\n",
    "    \"top_p\":0.95, \n",
    "    \"num_beams\":4,\n",
    "}\n",
    "\n",
    "\n",
    "attacks = generate_texts(multitask_model, tokenizer, test_df, gen_kwargs, 'counter_gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1668c745c2d54430a8c830c5fd0378ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_kwargs = {\n",
    "    \"do_sample\": False, \n",
    "    \"max_length\":100,\n",
    "    \"min_length\":10,\n",
    "    \"num_beams\":4,\n",
    "}\n",
    "\n",
    "conclusions = generate_texts(multitask_model, tokenizer, test_df, gen_kwargs, 'conclusion_gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['post_conclusion'] = conclusions\n",
    "test_df['post_counter'] = attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_pickle('../data/output/ca-final-models/mt-v2/predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post_conclusion</th>\n",
       "      <th>post_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410850</th>\n",
       "      <td>people should come with instructions</td>\n",
       "      <td>We should have an electronic signature on our introduction to meet people.</td>\n",
       "      <td>i don't think it's a good idea to have a social contract, but i think it would be a great idea if we could just instantly avoid people or gravitate toward some. if you're an introvert, you're probably not going to be a good friend, but if you are an extrovert, then you're going to become a great friend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410858</th>\n",
       "      <td>People should not be heavily criticized for things they put on social media in the distant past</td>\n",
       "      <td>I think it is unfair for the internet to come down hard on people for things they put on social media a long time ago.</td>\n",
       "      <td>i think it is unfair for the internet to come down hard on people for things they put on social media a long time ago. the internet is a place for people to express their opinions, and it is not a place where they should be held accountable for what they say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410902</th>\n",
       "      <td>We shouldn't focus on slowing climate change</td>\n",
       "      <td>There is no good reason to reduce CO2 emissions.</td>\n",
       "      <td>climate change is not a problem that can be solved by reducing co2 emissions. it is a problem. it's a problem we need to deal with, but it's not the only one. there are many other environmental issues that are more important than climate change. for example, global warming is a major threat to the environment, and it's going to be a problem for a long time to come. the problem is that we don't know what to do about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410910</th>\n",
       "      <td>The Australian PM was right to tell students to stop activism around global warming</td>\n",
       "      <td>I believe that climate change is real and that activism is not the right way to combat it.</td>\n",
       "      <td>i don't think it's fair to say that climate change is the most important issue in the world right now, but it's certainly one of the most pressing issues of our time. it's not that we can't do anything about it, it's that we don't know what we can do about it. we have a lot of information about the effects of climate change, but we have no way of knowing how much of it we can actually do. there's a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410916</th>\n",
       "      <td>Feeding cats or dogs a diet with meat is indefensible.</td>\n",
       "      <td>If you feed your cat dog meat, you're responsible for the deaths of 100s of smarter animals such as pigs.</td>\n",
       "      <td>i don't think it's fair to call people who feed their pets vegan diets shit like 'animal abusers' because they don't kill any animals. it's not like they're killing 100s of animals to sustain just one of them. they're doing so because they're trying to save the lives of other animals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410927</th>\n",
       "      <td>For a government to allow Hate Speech on the basis of Free Speech they must also abolish Copyright.</td>\n",
       "      <td>Copyright should be abolished and replaced with a right to hate speech.</td>\n",
       "      <td>the problem with this argument is that it ignores the fact that the first amendment is a document that was written in the early 20th century. it was written to protect freedom of speech, not freedom of expression. it is not about freedom of the press, it is about freedom from government interference in the free speech of the people. it's not about the right to free speech, it's about free speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410940</th>\n",
       "      <td>Cmv: if you are against legal abortion then you are for illegal abortion.</td>\n",
       "      <td>Banning abortion would be a win for black market abortion clinics</td>\n",
       "      <td>the problem with banning abortion is that it's not a solution to the problem of abortion. it's a solution for a problem that doesn't exist. the problem with abortion is not that there is a demand for it, it's that there isn't a market for it. there is no market for abortion. the market for abortions is that there are people who don't want to have a baby, but they don't have the money to pay for a doctor to do it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410964</th>\n",
       "      <td>The job market in the US has never been better.</td>\n",
       "      <td>The US is the best job market in US history.</td>\n",
       "      <td>i don't think it's fair to say that the unemployment rate is the lowest its been since 1969. it's the lowest it's ever been since the bls began recording data, and it's not even close to the lowest unemployment rate in the past 50 years. the real unemployment rate has been rising for decades, but it's been steadily increasing since the early 1970s. if you look at the black unemployment rate, we see that it's at its lowest its ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410971</th>\n",
       "      <td>Men and women should not be treated the same when it comes to sexual harrassment</td>\n",
       "      <td>Men who have been sexually harassed should be treated equally as women who are sexually harassed.</td>\n",
       "      <td>i don't think it's fair to say that men should be treated equally as women when they are catcalled, but i think that it's unfair to treat men equally when they have been catcalled. it's not fair to treat women equally because they are more likely to be catcalled than men, but it is unfair because it's a violation of their rights.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410991</th>\n",
       "      <td>All couples must undergo standarized tests in order to conceive and have children</td>\n",
       "      <td>I believe that parents should be required to pass some sort of test before having children.</td>\n",
       "      <td>the problem with this is that it's not about the children, it's about the parents. if you want to have children, you need to have a system in place to ensure that the children are raised in a way that is safe, healthy, and well cared for. the problem is that there is no such thing as'safe' or 'healthy' for the child. it's a matter of the child's well being, not the parents' well being. if</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       title  \\\n",
       "410850                                                                  people should come with instructions   \n",
       "410858       People should not be heavily criticized for things they put on social media in the distant past   \n",
       "410902                                                          We shouldn't focus on slowing climate change   \n",
       "410910                   The Australian PM was right to tell students to stop activism around global warming   \n",
       "410916                                                Feeding cats or dogs a diet with meat is indefensible.   \n",
       "410927   For a government to allow Hate Speech on the basis of Free Speech they must also abolish Copyright.   \n",
       "410940                             Cmv: if you are against legal abortion then you are for illegal abortion.   \n",
       "410964                                                       The job market in the US has never been better.   \n",
       "410971                      Men and women should not be treated the same when it comes to sexual harrassment   \n",
       "410991                     All couples must undergo standarized tests in order to conceive and have children   \n",
       "\n",
       "                                                                                                                post_conclusion  \\\n",
       "410850                                               We should have an electronic signature on our introduction to meet people.   \n",
       "410858   I think it is unfair for the internet to come down hard on people for things they put on social media a long time ago.   \n",
       "410902                                                                         There is no good reason to reduce CO2 emissions.   \n",
       "410910                               I believe that climate change is real and that activism is not the right way to combat it.   \n",
       "410916                If you feed your cat dog meat, you're responsible for the deaths of 100s of smarter animals such as pigs.   \n",
       "410927                                                  Copyright should be abolished and replaced with a right to hate speech.   \n",
       "410940                                                        Banning abortion would be a win for black market abortion clinics   \n",
       "410964                                                                             The US is the best job market in US history.   \n",
       "410971                        Men who have been sexually harassed should be treated equally as women who are sexually harassed.   \n",
       "410991                             I believe that parents should be required to pass some sort of test before having children.    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                              post_counter  \n",
       "410850                                                                                                                                    i don't think it's a good idea to have a social contract, but i think it would be a great idea if we could just instantly avoid people or gravitate toward some. if you're an introvert, you're probably not going to be a good friend, but if you are an extrovert, then you're going to become a great friend.  \n",
       "410858                                                                                                                                                                                 i think it is unfair for the internet to come down hard on people for things they put on social media a long time ago. the internet is a place for people to express their opinions, and it is not a place where they should be held accountable for what they say.  \n",
       "410902              climate change is not a problem that can be solved by reducing co2 emissions. it is a problem. it's a problem we need to deal with, but it's not the only one. there are many other environmental issues that are more important than climate change. for example, global warming is a major threat to the environment, and it's going to be a problem for a long time to come. the problem is that we don't know what to do about it.  \n",
       "410910                                   i don't think it's fair to say that climate change is the most important issue in the world right now, but it's certainly one of the most pressing issues of our time. it's not that we can't do anything about it, it's that we don't know what we can do about it. we have a lot of information about the effects of climate change, but we have no way of knowing how much of it we can actually do. there's a  \n",
       "410916                                                                                                                                                       i don't think it's fair to call people who feed their pets vegan diets shit like 'animal abusers' because they don't kill any animals. it's not like they're killing 100s of animals to sustain just one of them. they're doing so because they're trying to save the lives of other animals.  \n",
       "410927                                     the problem with this argument is that it ignores the fact that the first amendment is a document that was written in the early 20th century. it was written to protect freedom of speech, not freedom of expression. it is not about freedom of the press, it is about freedom from government interference in the free speech of the people. it's not about the right to free speech, it's about free speech.  \n",
       "410940                     the problem with banning abortion is that it's not a solution to the problem of abortion. it's a solution for a problem that doesn't exist. the problem with abortion is not that there is a demand for it, it's that there isn't a market for it. there is no market for abortion. the market for abortions is that there are people who don't want to have a baby, but they don't have the money to pay for a doctor to do it  \n",
       "410964  i don't think it's fair to say that the unemployment rate is the lowest its been since 1969. it's the lowest it's ever been since the bls began recording data, and it's not even close to the lowest unemployment rate in the past 50 years. the real unemployment rate has been rising for decades, but it's been steadily increasing since the early 1970s. if you look at the black unemployment rate, we see that it's at its lowest its ever  \n",
       "410971                                                                                                         i don't think it's fair to say that men should be treated equally as women when they are catcalled, but i think that it's unfair to treat men equally when they have been catcalled. it's not fair to treat women equally because they are more likely to be catcalled than men, but it is unfair because it's a violation of their rights.  \n",
       "410991                                             the problem with this is that it's not about the children, it's about the parents. if you want to have children, you need to have a system in place to ensure that the children are raised in a way that is safe, healthy, and well cared for. the problem is that there is no such thing as'safe' or 'healthy' for the child. it's a matter of the child's well being, not the parents' well being. if  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['title', 'post_conclusion', 'post_counter']].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
